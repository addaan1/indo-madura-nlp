{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14135617,"sourceType":"datasetVersion","datasetId":9007649},{"sourceId":14137861,"sourceType":"datasetVersion","datasetId":9009334}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U indobenchmark-toolkit evaluate sacrebleu rouge-score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U transformers accelerate evaluate sacrebleu rouge-score sentencepiece\n","metadata":{"execution":{"iopub.execute_input":"2025-12-14T11:25:18.255663Z","iopub.status.busy":"2025-12-14T11:25:18.254072Z","iopub.status.idle":"2025-12-14T11:25:35.866433Z","shell.execute_reply":"2025-12-14T11:25:35.865495Z","shell.execute_reply.started":"2025-12-14T11:25:18.255636Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n","Collecting transformers\n","  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n","Collecting accelerate\n","  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.6)\n","Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\n","Requirement already satisfied: rouge-score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.2.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\n","Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n","  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.1.3)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.4.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.4.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.18)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.2.0)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.2)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n","Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (22.0.0)\n","Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n","Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.3.0)\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.3.0)\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.10.5)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.3.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.5.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n","Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2025.3.0)\n","Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.3.0)\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\n","Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:01\u001b[0m\n","\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sentencepiece-0.2.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece, tokenizers, transformers, accelerate\n","  Attempting uninstall: sentencepiece\n","    Found existing installation: sentencepiece 0.2.0\n","    Uninstalling sentencepiece-0.2.0:\n","      Successfully uninstalled sentencepiece-0.2.0\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.21.2\n","    Uninstalling tokenizers-0.21.2:\n","      Successfully uninstalled tokenizers-0.21.2\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.53.3\n","    Uninstalling transformers-4.53.3:\n","      Successfully uninstalled transformers-4.53.3\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 1.9.0\n","    Uninstalling accelerate-1.9.0:\n","      Successfully uninstalled accelerate-1.9.0\n","Successfully installed accelerate-1.12.0 sentencepiece-0.2.1 tokenizers-0.22.1 transformers-4.57.3\n"]}],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n\nimport os, re, unicodedata\nimport numpy as np\nimport pandas as pd\n\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSeq2SeqLM,\n    DataCollatorForSeq2Seq,\n    Trainer,\n    TrainingArguments,\n    EarlyStoppingCallback\n)\n\nimport evaluate\nprint(\"evaluate version:\", evaluate.__version__)\n\n# >>> ADDED: tokenizer khusus IndoBenchmark\nfrom indobenchmark import IndoNLGTokenizer","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport unicodedata\nimport numpy as np\n\nIN_PATH  = \"/kaggle/input/inmad-dataset/INMAD Dataset.csv\"\nOUT_PATH = \"inmad_clean_v2.csv\"\n\ndef fix_mojibake(s: str) -> str:\n    if not isinstance(s, str):\n        s = \"\" if s is None else str(s)\n\n    # heuristik sederhana: kalau ada √É/√Ç/ÔøΩ biasanya mojibake\n    if any(ch in s for ch in [\"√É\", \"√Ç\", \"ÔøΩ\", \"\\uFFFD\"]):\n        for src_enc in [\"latin-1\", \"cp1252\"]:\n            try:\n                s2 = s.encode(src_enc, errors=\"ignore\").decode(\"utf-8\", errors=\"ignore\")\n                if len(s2.strip()) > 0:\n                    s = s2\n                    break\n            except Exception:\n                pass\n    return s\n\ndef normalize_text(s: str) -> str:\n    s = fix_mojibake(s)\n    s = unicodedata.normalize(\"NFKC\", s)\n\n    # hapus control chars\n    s = re.sub(r\"[\\u0000-\\u001F\\u007F-\\u009F]\", \" \", s)\n    s = s.replace(\"\\u200b\", \" \").replace(\"\\ufeff\", \" \")\n\n    # normalisasi kutip/apostrof\n    s = (s.replace(\"‚Äô\",\"'\").replace(\"‚Äò\",\"'\").replace(\"¬¥\",\"'\").replace(\"`\",\"'\")\n           .replace(\"‚Äú\",'\"').replace(\"‚Äù\",'\"'))\n\n    # normalisasi dash dan ellipsis\n    s = s.replace(\"‚Äì\",\"-\").replace(\"‚Äî\",\"-\").replace(\"‚àí\",\"-\")\n    s = s.replace(\"‚Ä¶\",\"...\")\n\n    # rapikan spasi\n    s = re.sub(r\"\\s+\", \" \", s).strip()\n\n    # hilangkan spasi sebelum tanda baca: \" ,\", \" .\", dst\n    s = re.sub(r\"\\s+([,.;:!?])\", r\"\\1\", s)\n\n    # pastikan ada spasi setelah tanda baca jika langsung diikuti huruf/angka\n    s = re.sub(r\"([,;:!?])([A-Za-z0-9])\", r\"\\1 \\2\", s)\n    s = re.sub(r\"(\\.)([A-Za-z])\", r\"\\1 \\2\", s)  # \".kata\" -> \". kata\"\n\n    # rapikan kurung/bracket\n    s = re.sub(r\"\\(\\s+\", \"(\", s)\n    s = re.sub(r\"\\s+\\)\", \")\", s)\n    s = re.sub(r\"\\[\\s+\", \"[\", s)\n    s = re.sub(r\"\\s+\\]\", \"]\", s)\n\n    # collapse multi punctuation\n    s = re.sub(r\"([!?])\\1{1,}\", r\"\\1\", s)\n    s = re.sub(r\"\\.{4,}\", \"...\", s)\n\n    return s\n\ndef tok_len(s: str) -> int:\n    return len(re.findall(r\"\\S+\", str(s)))\n\n# ===== Load =====\nraw = pd.read_csv(IN_PATH)\n\n# Ambil kolom yang kita butuhkan: Indonesia & Madura (buang English)\ndf = raw.rename(columns={\"Indonesia\":\"id\", \"Madura\":\"mad\"}).copy()\ndf[\"id\"]  = df[\"id\"].astype(str).map(normalize_text)\ndf[\"mad\"] = df[\"mad\"].astype(str).map(normalize_text)\n\n# drop kosong + dedup\ndf = df[(df[\"id\"] != \"\") & (df[\"mad\"] != \"\")]\ndf = df.drop_duplicates(subset=[\"id\",\"mad\"]).reset_index(drop=True)\n\n# ===== Filter kualitas (biar tidak over-noisy) =====\nid_len  = df[\"id\"].map(tok_len)\nmad_len = df[\"mad\"].map(tok_len)\nratio   = (id_len + 1) / (mad_len + 1)\n\n# batas aman (kamu bisa adjust)\nkeep = (\n    (id_len  >= 3)  & (mad_len >= 3) &\n    (id_len  <= 200) & (mad_len <= 220) &\n    (ratio >= 0.5) & (ratio <= 2.0)\n)\n\ndf_clean = df[keep].reset_index(drop=True)\n\nprint(\"Raw rows:\", len(raw))\nprint(\"After basic clean:\", len(df))\nprint(\"After filter:\", len(df_clean))\n\n# ===== Save =====\ndf_clean[[\"id\",\"mad\"]].to_csv(OUT_PATH, index=False)\nprint(\"Saved:\", OUT_PATH)\n","metadata":{"execution":{"iopub.status.busy":"2025-12-14T12:53:37.349542Z","iopub.execute_input":"2025-12-14T12:53:37.350009Z","iopub.status.idle":"2025-12-14T12:53:39.663042Z","shell.execute_reply.started":"2025-12-14T12:53:37.349986Z","shell.execute_reply":"2025-12-14T12:53:39.662357Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Raw rows: 23098\nAfter basic clean: 23032\nAfter filter: 21389\nSaved: inmad_clean_v2.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# MODEL\nMODEL_NAME = \"indobenchmark/indobart-v2\"\n","metadata":{"execution":{"iopub.execute_input":"2025-12-14T11:30:13.140495Z","iopub.status.busy":"2025-12-14T11:30:13.139578Z","iopub.status.idle":"2025-12-14T11:30:13.146488Z","shell.execute_reply":"2025-12-14T11:30:13.144437Z","shell.execute_reply.started":"2025-12-14T11:30:13.140463Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Isi BASE_PATH:\n","['valid.csv', 'test.csv', 'train.csv', 'madurese.csv']\n"]}],"execution_count":null},{"cell_type":"markdown","source":"# prepro","metadata":{}},{"cell_type":"code","source":"def standardize_cols(df: pd.DataFrame) -> pd.DataFrame:\n    cols = {c.lower(): c for c in df.columns}\n    id_col  = cols.get(\"indonesian\") or cols.get(\"id\") or cols.get(\"indo\") or cols.get(\"source\")\n    mad_col = cols.get(\"madurese\") or cols.get(\"mad\") or cols.get(\"madura\") or cols.get(\"target\")\n    if id_col is None or mad_col is None:\n        raise ValueError(f\"Kolom id/mad tidak ketemu. Kolom yang ada: {list(df.columns)}\")\n    out = df[[id_col, mad_col]].copy()\n    out.columns = [\"id\", \"mad\"]\n    return out\n\ndef fix_mojibake(s: str) -> str:\n    if not isinstance(s, str):\n        s = \"\" if s is None else str(s)\n\n    # heuristik sederhana: kalau ada √É/√Ç/ÔøΩ biasanya mojibake\n    if any(ch in s for ch in [\"√É\", \"√Ç\", \"ÔøΩ\", \"\\uFFFD\"]):\n        for src_enc in [\"latin-1\", \"cp1252\"]:\n            try:\n                s2 = s.encode(src_enc, errors=\"ignore\").decode(\"utf-8\", errors=\"ignore\")\n                if len(s2.strip()) > 0:\n                    s = s2\n                    break\n            except Exception:\n                pass\n    return s\ndef clean_text(s: str) -> str:\n    s = fix_mojibake(s)\n    s = s.replace(\"\\u200b\", \" \").replace(\"\\ufeff\", \" \")\n    s = re.sub(r\"\\s+\", \" \", s).strip()\n    return s\n\ndef clean_df(df: pd.DataFrame) -> pd.DataFrame:\n    df = df.copy()\n    df[\"id\"]  = df[\"id\"].map(clean_text)\n    df[\"mad\"] = df[\"mad\"].map(clean_text)\n    df = df[(df[\"id\"] != \"\") & (df[\"mad\"] != \"\")]\n    df = df.drop_duplicates(subset=[\"id\",\"mad\"]).reset_index(drop=True)\n    return df\n\ndef drop_unnamed_cols(df: pd.DataFrame) -> pd.DataFrame:\n    unnamed = [c for c in df.columns if str(c).lower().startswith(\"unnamed\")]\n    if unnamed:\n        df = df.drop(columns=unnamed)\n    return df\n\ndef guess_column(df: pd.DataFrame, candidates):\n    cols_lower = {c.lower(): c for c in df.columns}\n    for cand in candidates:\n        if cand.lower() in cols_lower:\n            return cols_lower[cand.lower()]\n    return None","metadata":{"execution":{"iopub.status.busy":"2025-12-14T12:53:45.318541Z","iopub.execute_input":"2025-12-14T12:53:45.318813Z","iopub.status.idle":"2025-12-14T12:53:45.329188Z","shell.execute_reply.started":"2025-12-14T12:53:45.318794Z","shell.execute_reply":"2025-12-14T12:53:45.328637Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# import data","metadata":{}},{"cell_type":"code","source":"\nnusax_train = clean_df(standardize_cols(pd.read_csv(\"/kaggle/input/nusaxdata/train.csv\")))\nnusax_valid = clean_df(standardize_cols(pd.read_csv(\"/kaggle/input/nusaxdata/valid.csv\")))\nnusax_test  = clean_df(standardize_cols(pd.read_csv(\"/kaggle/input/nusaxdata/test (1).csv\")))  # sesuaikan nama file test kamu\n\nprint(len(nusax_train), len(nusax_valid), len(nusax_test))\n","metadata":{"execution":{"iopub.status.busy":"2025-12-14T12:53:50.094757Z","iopub.execute_input":"2025-12-14T12:53:50.095029Z","iopub.status.idle":"2025-12-14T12:53:50.168819Z","shell.execute_reply.started":"2025-12-14T12:53:50.095007Z","shell.execute_reply":"2025-12-14T12:53:50.168053Z"},"trusted":true},"outputs":[{"name":"stdout","text":"500 100 400\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"lex = pd.read_csv(\"/kaggle/input/nusaxdata/madurese.csv\")  # file lexicon\nlex = standardize_cols(lex)        # jadi id, mad\nlex = clean_df(lex)\n\n# bikin mapping mad->mad \"kanonik\" berbasis bentuk yang paling sering / paling pendek\n# (ini sederhana tapi efektif untuk merapikan variasi ejaan)\nmad2canon = {}\nfor _, r in lex.iterrows():\n    m = r[\"mad\"]\n    # pilih bentuk canon = bentuk yang \"paling clean\" (panjang paling pendek)\n    if m not in mad2canon:\n        mad2canon[m] = m\n\n# kalau kamu mau mapping variasi ke satu bentuk (misal bul√¢ vs bula'), kamu butuh aturan tambahan.\n# Untuk versi aman: kita pakai normalisasi karakter saja + perbaiki mojibake.\ndef normalize_madurese_with_lexicon(text: str) -> str:\n    # perbaiki encoding & rapikan spasi (yang paling aman)\n    return clean_text(text)\n","metadata":{"execution":{"iopub.status.busy":"2025-12-14T12:54:03.743007Z","iopub.execute_input":"2025-12-14T12:54:03.743612Z","iopub.status.idle":"2025-12-14T12:54:03.809609Z","shell.execute_reply.started":"2025-12-14T12:54:03.743584Z","shell.execute_reply":"2025-12-14T12:54:03.809057Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"inmad = pd.read_csv(\"inmad_clean_v2.csv\")\n\n\n# normalisasi madurese pakai fungsi lexicon (safe)\ninmad[\"mad\"] = inmad[\"mad\"].map(normalize_madurese_with_lexicon)\n\nprint(\"inmad:\", len(inmad))\n","metadata":{"execution":{"iopub.status.busy":"2025-12-14T12:54:06.533957Z","iopub.execute_input":"2025-12-14T12:54:06.534581Z","iopub.status.idle":"2025-12-14T12:54:06.814406Z","shell.execute_reply.started":"2025-12-14T12:54:06.534556Z","shell.execute_reply":"2025-12-14T12:54:06.813562Z"},"trusted":true},"outputs":[{"name":"stdout","text":"inmad: 21389\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"rng = np.random.default_rng(42)\nidx = np.arange(len(inmad))\nrng.shuffle(idx)\n\nvalid_frac = 0.05   # 5% valid dari InMad\nn_valid = max(1, int(len(inmad) * valid_frac))\n\ninmad_valid = inmad.iloc[idx[:n_valid]].reset_index(drop=True)\ninmad_train = inmad.iloc[idx[n_valid:]].reset_index(drop=True)\n\n# (opsional) kalau InMad jauh lebih besar, batasi rasio biar NusaX nggak ketimbun\nmax_ratio = 3  # InMad train max 3x NusaX train\ntarget_inmad = min(len(inmad_train), max_ratio * len(nusax_train))\ninmad_train = inmad_train.sample(n=target_inmad, random_state=42).reset_index(drop=True)\n\n# tag sumber (optional tapi bagus buat kontrol domain)\nnusax_train[\"src\"] = \"nusax\"\nnusax_valid[\"src\"] = \"nusax\"\ninmad_train[\"src\"] = \"inmad\"\ninmad_valid[\"src\"] = \"inmad\"\n\ntrain_mix = pd.concat([nusax_train, inmad_train], ignore_index=True)\nvalid_mix = pd.concat([nusax_valid, inmad_valid], ignore_index=True)\n\nprint(\"train_mix:\", len(train_mix), \"valid_mix:\", len(valid_mix))\n","metadata":{"execution":{"iopub.status.busy":"2025-12-14T12:54:09.112227Z","iopub.execute_input":"2025-12-14T12:54:09.112954Z","iopub.status.idle":"2025-12-14T12:54:09.128755Z","shell.execute_reply.started":"2025-12-14T12:54:09.112927Z","shell.execute_reply":"2025-12-14T12:54:09.127871Z"},"trusted":true},"outputs":[{"name":"stdout","text":"train_mix: 2000 valid_mix: 1169\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def build_bidirectional(df: pd.DataFrame) -> Dataset:\n    rows = []\n    for _, r in df.iterrows():\n        rows.append({\n            \"direction\": \"id2mad\",\n            \"source\": \"translate Indonesian to Madurese: \" + r[\"id\"],\n            \"target\": r[\"mad\"]\n        })\n        rows.append({\n            \"direction\": \"mad2id\",\n            \"source\": \"translate Madurese to Indonesian: \" + r[\"mad\"],\n            \"target\": r[\"id\"]\n        })\n    return Dataset.from_pandas(pd.DataFrame(rows))\n\ntrain_ds = build_bidirectional(train_mix)\nvalid_ds = build_bidirectional(valid_mix)\ntest_ds  = build_bidirectional(nusax_test)\n\ntrain_ds[0], train_ds[1]\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# model","metadata":{}},{"cell_type":"code","source":"from indobenchmark import IndoNLGTokenizer\n\n# 1) RESET tokenizer (fresh instance)\ntokenizer = IndoNLGTokenizer.from_pretrained(MODEL_NAME)\n\n# 2) PATCH pad yang kebal rerun (ambil pad dari CLASS, bukan dari instance)\n_base_pad = tokenizer.__class__.pad  # ini selalu \"pad asli\" dari kelas, bukan yang kepatch instance\n\ndef pad_compat(encoded_inputs, *args, **kwargs):\n    kwargs.pop(\"padding_side\", None)\n    kwargs.pop(\"return_tensors\", None)\n    return _base_pad(tokenizer, encoded_inputs, *args, **kwargs)\n\ntokenizer.pad = pad_compat\n","metadata":{"execution":{"iopub.execute_input":"2025-12-14T12:16:42.835170Z","iopub.status.busy":"2025-12-14T12:16:42.834576Z","iopub.status.idle":"2025-12-14T12:16:43.417629Z","shell.execute_reply":"2025-12-14T12:16:43.417047Z","shell.execute_reply.started":"2025-12-14T12:16:42.835144Z"},"trusted":true},"outputs":[],"execution_count":35},{"cell_type":"code","source":"MAX_LEN_SRC = 128\nMAX_LEN_TGT = 128\n\ndef tokenize_batch(batch):\n    inputs = tokenizer(\n        batch[\"source\"],\n        truncation=True,\n        max_length=MAX_LEN_SRC\n    )\n\n    labels = tokenizer(\n        batch[\"target\"],\n        truncation=True,\n        max_length=MAX_LEN_TGT\n    )\n\n    inputs[\"labels\"] = labels[\"input_ids\"]\n    return inputs\n","metadata":{"execution":{"iopub.execute_input":"2025-12-14T12:16:56.656391Z","iopub.status.busy":"2025-12-14T12:16:56.656107Z","iopub.status.idle":"2025-12-14T12:16:56.660944Z","shell.execute_reply":"2025-12-14T12:16:56.660233Z","shell.execute_reply.started":"2025-12-14T12:16:56.656370Z"},"trusted":true},"outputs":[],"execution_count":36},{"cell_type":"code","source":"train_tok = train_ds.map(tokenize_batch, batched=True, remove_columns=train_ds.column_names)\nvalid_tok = valid_ds.map(tokenize_batch, batched=True, remove_columns=valid_ds.column_names)\ntest_tok  = test_ds.map(tokenize_batch,  batched=True, remove_columns=test_ds.column_names)\n","metadata":{"execution":{"iopub.execute_input":"2025-12-14T12:17:03.372393Z","iopub.status.busy":"2025-12-14T12:17:03.372115Z","iopub.status.idle":"2025-12-14T12:17:04.362797Z","shell.execute_reply":"2025-12-14T12:17:04.362240Z","shell.execute_reply.started":"2025-12-14T12:17:03.372376Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d0696606995420aa15a868c2c11f665","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71a14d0054a74b6d848fa6d7c186aeff","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/200 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf89acbe753245658a18599011567e43","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/800 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"execution_count":37},{"cell_type":"code","source":"train_tok.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\nvalid_tok.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\ntest_tok.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n","metadata":{"execution":{"iopub.execute_input":"2025-12-14T12:21:37.464816Z","iopub.status.busy":"2025-12-14T12:21:37.464032Z","iopub.status.idle":"2025-12-14T12:21:37.470523Z","shell.execute_reply":"2025-12-14T12:21:37.469971Z","shell.execute_reply.started":"2025-12-14T12:21:37.464790Z"},"trusted":true},"outputs":[],"execution_count":48},{"cell_type":"code","source":"print(train_tok[0])","metadata":{"execution":{"iopub.execute_input":"2025-12-14T12:22:37.418278Z","iopub.status.busy":"2025-12-14T12:22:37.417593Z","iopub.status.idle":"2025-12-14T12:22:37.428426Z","shell.execute_reply":"2025-12-14T12:22:37.427748Z","shell.execute_reply.started":"2025-12-14T12:22:37.418253Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': tensor([23353, 13807,  1358,  1922,   310,  5988, 39969,  7841, 14917,   609,\n","        39991,  1025,  1301,  1159,   365,  4067,  1574,  1896,   887,  3364,\n","          354,  1835,  3549,  9864, 39981]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1]), 'labels': tensor([ 7841, 19380,  3704,   609, 39991,   656,   352,  1301,  2103,   262,\n","         7205,   390,  6181,  2030,  1523,  4376, 34897,  2828,   887,  3364,\n","        11509,  1835,  3549,  9864, 39981])}\n"]}],"execution_count":49},{"cell_type":"code","source":"import torch\nfrom torch.nn.utils.rnn import pad_sequence\n\nclass TorchPadSeq2SeqCollator:\n    def __init__(self, pad_token_id, label_pad_token_id=-100):\n        self.pad_token_id = pad_token_id\n        self.label_pad_token_id = label_pad_token_id\n\n    def __call__(self, features):\n        # features: list of dicts with torch tensors (seperti yang kamu tunjukkan)\n        input_ids = [f[\"input_ids\"] for f in features]\n        attention_mask = [f[\"attention_mask\"] for f in features]\n        labels = [f[\"labels\"] for f in features]\n\n        input_ids = pad_sequence(input_ids, batch_first=True, padding_value=self.pad_token_id)\n        attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n        labels = pad_sequence(labels, batch_first=True, padding_value=self.label_pad_token_id)\n\n        return {\n            \"input_ids\": input_ids,\n            \"attention_mask\": attention_mask,\n            \"labels\": labels,\n        }\n\n# pakai ini sebagai data_collator\ndata_collator = TorchPadSeq2SeqCollator(\n    pad_token_id=tokenizer.pad_token_id,\n    label_pad_token_id=-100\n)\n","metadata":{"execution":{"iopub.execute_input":"2025-12-14T12:23:18.939936Z","iopub.status.busy":"2025-12-14T12:23:18.939659Z","iopub.status.idle":"2025-12-14T12:23:18.945804Z","shell.execute_reply":"2025-12-14T12:23:18.945071Z","shell.execute_reply.started":"2025-12-14T12:23:18.939916Z"},"trusted":true},"outputs":[],"execution_count":51},{"cell_type":"code","source":"bleu = evaluate.load(\"sacrebleu\")\nrouge = evaluate.load(\"rouge\")\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n\n    # >>> ADDED: preds kadang tuple\n    if isinstance(preds, tuple):\n        preds = preds[0]\n\n    pred_texts = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    ref_texts = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    bleu_score = bleu.compute(predictions=pred_texts, references=[[r] for r in ref_texts])[\"score\"]\n    rouge_score = rouge.compute(predictions=pred_texts, references=ref_texts)\n\n    return {\n        \"bleu\": bleu_score,\n        \"rouge1\": rouge_score[\"rouge1\"],\n        \"rougeL\": rouge_score[\"rougeL\"]\n    }\n","metadata":{"execution":{"iopub.execute_input":"2025-12-14T12:23:21.626020Z","iopub.status.busy":"2025-12-14T12:23:21.625472Z","iopub.status.idle":"2025-12-14T12:23:22.586872Z","shell.execute_reply":"2025-12-14T12:23:22.586065Z","shell.execute_reply.started":"2025-12-14T12:23:21.625980Z"},"trusted":true},"outputs":[],"execution_count":52},{"cell_type":"code","source":"import transformers, sys\nprint(\"transformers version:\", transformers.__version__)\nprint(\"python:\", sys.version)\n\nOUTPUT_DIR = \"./indobenchmark-indobart-v2\"\n\ntraining_args = TrainingArguments(\n    output_dir=OUTPUT_DIR,\n    save_steps=10**9,        # praktis tidak pernah save checkpoint\n    save_total_limit=1,\n    logging_steps=100,\n    learning_rate=3e-5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=1,\n    num_train_epochs=10,\n    fp16=True,\n    report_to=\"none\",\n    prediction_loss_only=True,\n)","metadata":{"execution":{"iopub.execute_input":"2025-12-14T12:23:25.590359Z","iopub.status.busy":"2025-12-14T12:23:25.590090Z","iopub.status.idle":"2025-12-14T12:23:25.626945Z","shell.execute_reply":"2025-12-14T12:23:25.626131Z","shell.execute_reply.started":"2025-12-14T12:23:25.590340Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["transformers version: 4.57.3\n","python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n"]}],"execution_count":53},{"cell_type":"code","source":"import transformers, sys\nprint(\"transformers version:\", transformers.__version__)\nprint(\"python:\", sys.version)\n\nOUTPUT_DIR = \"./indobenchmark-indobart-v2\"\n\n# ======================\n# 1) PATCH: cegah autosave tokenizer (IndoNLGTokenizer tidak support save_vocabulary)\n# ======================\ndef _noop_save_pretrained(*args, **kwargs):\n    return ()\n\ntokenizer.save_pretrained = _noop_save_pretrained\ntokenizer.save_vocabulary = lambda *args, **kwargs: ()\n\n# ======================\n# 2) TrainingArguments (aman lintas versi)\n# ======================\ntraining_args = TrainingArguments(\n    output_dir=OUTPUT_DIR,\n    save_steps=10**9,          # praktis tidak pernah save checkpoint\n    save_total_limit=1,\n    logging_steps=100,\n\n    # ‚ùå JANGAN pakai evaluation_strategy (versi transformers lama)\n    prediction_loss_only=False,   # ‚úÖ wajib False\n\n    learning_rate=3e-5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=1,\n    num_train_epochs=10,\n\n    fp16=True,\n    report_to=\"none\",\n)\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n\n    # ‚úÖ IndoNLGTokenizer-safe decoding (hindari batch_decode)\n    pred_texts = [tokenizer.decode(p, skip_special_tokens=True) for p in preds]\n\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    ref_texts = [tokenizer.decode(l, skip_special_tokens=True) for l in labels]\n\n    bleu_score = bleu.compute(predictions=pred_texts, references=[[r] for r in ref_texts])[\"score\"]\n    rouge_score = rouge.compute(predictions=pred_texts, references=ref_texts)\n\n    return {\n        \"bleu\": bleu_score,\n        \"rouge1\": rouge_score[\"rouge1\"],\n        \"rougeL\": rouge_score[\"rougeL\"],\n    }\n\n# ======================\n# 3) BLEU per epoch callback + AVG + summary\n# ======================\nimport torch\nimport sacrebleu\nfrom transformers import TrainerCallback\n\nBLEU_LOG = {}  # {epoch_int: {\"id2mad\":..., \"mad2id\":..., \"avg\":...}}\n\ndef _epoch_key(state):\n    if state.epoch is None:\n        return int(getattr(state, \"global_step\", 0))\n    return int(state.epoch)\n\nclass BleuEachEpochCallback(TrainerCallback):\n    def __init__(self, tokenizer, valid_df, direction=\"id2mad\", n_samples=100,\n                 max_len_src=128, max_new_tok=128, batch_size=8, num_beams=4):\n        self.tokenizer = tokenizer\n        self.valid_df = valid_df\n        self.direction = direction\n        self.n_samples = n_samples\n        self.max_len_src = max_len_src\n        self.max_new_tok = max_new_tok\n        self.batch_size = batch_size\n        self.num_beams = num_beams\n\n    def on_epoch_end(self, args, state, control, **kwargs):\n        model = kwargs[\"model\"]\n        device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        model.eval()\n\n        df = self.valid_df.head(self.n_samples)\n\n        if self.direction == \"id2mad\":\n            sources = [\"translate Indonesian to Madurese: \" + x for x in df[\"id\"].tolist()]\n            refs = df[\"mad\"].tolist()\n        else:\n            sources = [\"translate Madurese to Indonesian: \" + x for x in df[\"mad\"].tolist()]\n            refs = df[\"id\"].tolist()\n\n        preds = []\n        with torch.no_grad():\n            for i in range(0, len(sources), self.batch_size):\n                batch = sources[i:i+self.batch_size]\n                enc = self.tokenizer(\n                    batch,\n                    return_tensors=\"pt\",\n                    padding=True,\n                    truncation=True,\n                    max_length=self.max_len_src\n                )\n                enc = {k: v.to(device) for k, v in enc.items()}\n                out = model.generate(\n                    **enc,\n                    max_new_tokens=self.max_new_tok,\n                    num_beams=self.num_beams,\n                    # OPTIONAL anti-loop (boleh aktifkan kalau sering repetisi)\n                    # no_repeat_ngram_size=3,\n                    # repetition_penalty=1.1,\n                    # early_stopping=True,\n                )\n\n                preds.extend([self.tokenizer.decode(o, skip_special_tokens=True) for o in out])\n\n        bleu_val = sacrebleu.corpus_bleu(preds, [refs]).score\n\n        ep = _epoch_key(state)\n        BLEU_LOG.setdefault(ep, {})\n        BLEU_LOG[ep][self.direction] = bleu_val\n\n        if \"id2mad\" in BLEU_LOG[ep] and \"mad2id\" in BLEU_LOG[ep]:\n            avg_bleu = (BLEU_LOG[ep][\"id2mad\"] + BLEU_LOG[ep][\"mad2id\"]) / 2.0\n            BLEU_LOG[ep][\"avg\"] = avg_bleu\n            print(\n                f\"\\nüèÜ Epoch {ep} | ID2MAD BLEU@{self.n_samples}: {BLEU_LOG[ep]['id2mad']:.2f} | \"\n                f\"MAD2ID BLEU@{self.n_samples}: {BLEU_LOG[ep]['mad2id']:.2f} | \"\n                f\"AVG: {avg_bleu:.2f}\\n\"\n            )\n        else:\n            print(f\"\\nüèÜ Epoch {ep} | {self.direction.upper()} BLEU@{self.n_samples}: {bleu_val:.2f}\\n\")\n\n        model.train()\n        return control\n\nclass BleuAvgSummaryCallback(TrainerCallback):\n    def on_train_end(self, args, state, control, **kwargs):\n        if not BLEU_LOG:\n            print(\"\\n‚ö†Ô∏è BLEU_LOG kosong (tidak ada BLEU yang tercatat)\\n\")\n            return control\n\n        print(\"\\n==============================\")\n        print(\"üìå RINGKASAN BLEU PER EPOCH (AVG)\")\n        print(\"==============================\")\n        for ep in sorted(BLEU_LOG.keys()):\n            rec = BLEU_LOG[ep]\n            id2 = rec.get(\"id2mad\", float(\"nan\"))\n            m2i = rec.get(\"mad2id\", float(\"nan\"))\n            avg = rec.get(\"avg\", float(\"nan\"))\n            print(f\"Epoch {ep}: ID2MAD={id2:.2f} | MAD2ID={m2i:.2f} | AVG={avg:.2f}\")\n\n        avgs = [BLEU_LOG[ep][\"avg\"] for ep in sorted(BLEU_LOG.keys()) if \"avg\" in BLEU_LOG[ep]]\n        if avgs:\n            overall = sum(avgs) / len(avgs)\n            print(\"------------------------------\")\n            print(f\"‚úÖ Overall AVG BLEU across epochs: {overall:.2f}\")\n        print(\"==============================\\n\")\n        return control\n\n# callbacks dua arah + summary\nbleu_cb_id2mad = BleuEachEpochCallback(\n    tokenizer=tokenizer,\n    valid_df=valid_mix,\n    direction=\"id2mad\",\n    n_samples=100,\n    max_len_src=128,\n    max_new_tok=128,\n    batch_size=8,\n    num_beams=4\n)\n\nbleu_cb_mad2id = BleuEachEpochCallback(\n    tokenizer=tokenizer,\n    valid_df=valid_mix,\n    direction=\"mad2id\",\n    n_samples=100,\n    max_len_src=128,\n    max_new_tok=128,\n    batch_size=8,\n    num_beams=4\n)\n\nbleu_summary = BleuAvgSummaryCallback()\n\n# ======================\n# 4) Trainer + train\n# ======================\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_tok,\n    eval_dataset=valid_tok,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,  # ‚úÖ kalau mau metric tampil di log\n    callbacks=[bleu_cb_id2mad, bleu_cb_mad2id, bleu_summary],\n)\n\ntrainer.train()\n\n# ======================\n# 5) Save model (tokenizer tidak disave)\n# ======================\ntrainer.save_model(OUTPUT_DIR)\nprint(\"‚úÖ Model disimpan ke:\", OUTPUT_DIR)\nprint(\"‚ÑπÔ∏è Tokenizer tidak disimpan (pakai tokenizer bawaan indobenchmark/indobart-v2).\")\n\nbest_ckpt = getattr(trainer.state, \"best_model_checkpoint\", None)\nbest_metric = getattr(trainer.state, \"best_metric\", None)\nprint(\"Best checkpoint:\", best_ckpt)\nprint(\"Best metric:\", best_metric)\n","metadata":{"execution":{"iopub.execute_input":"2025-12-14T12:23:27.956805Z","iopub.status.busy":"2025-12-14T12:23:27.956124Z","iopub.status.idle":"2025-12-14T12:35:08.211088Z","shell.execute_reply":"2025-12-14T12:35:08.210208Z","shell.execute_reply.started":"2025-12-14T12:23:27.956782Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["You are adding a <class '__main__.BleuEachEpochCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",":DefaultFlowCallback\n","BleuEachEpochCallback\n"]},{"name":"stdout","output_type":"stream","text":["transformers version: 4.57.3\n","python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1250/1250 11:38, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.899600</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.690100</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.545500</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.450300</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.367600</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.289400</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.254100</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.223800</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.201100</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.207900</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.195100</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.190800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","üèÜ Epoch 1 | ID2MAD BLEU@100: 15.75\n","\n","\n","üèÜ Epoch 1 | ID2MAD BLEU@100: 15.75 | MAD2ID BLEU@100: 21.33 | AVG: 18.54\n","\n","\n","üèÜ Epoch 2 | ID2MAD BLEU@100: 16.47\n","\n","\n","üèÜ Epoch 2 | ID2MAD BLEU@100: 16.47 | MAD2ID BLEU@100: 18.76 | AVG: 17.61\n","\n","\n","üèÜ Epoch 3 | ID2MAD BLEU@100: 12.50\n","\n","\n","üèÜ Epoch 3 | ID2MAD BLEU@100: 12.50 | MAD2ID BLEU@100: 16.31 | AVG: 14.40\n","\n","\n","üèÜ Epoch 4 | ID2MAD BLEU@100: 15.13\n","\n","\n","üèÜ Epoch 4 | ID2MAD BLEU@100: 15.13 | MAD2ID BLEU@100: 18.61 | AVG: 16.87\n","\n","\n","üèÜ Epoch 5 | ID2MAD BLEU@100: 15.35\n","\n","\n","üèÜ Epoch 5 | ID2MAD BLEU@100: 15.35 | MAD2ID BLEU@100: 19.74 | AVG: 17.55\n","\n","\n","üèÜ Epoch 6 | ID2MAD BLEU@100: 14.73\n","\n","\n","üèÜ Epoch 6 | ID2MAD BLEU@100: 14.73 | MAD2ID BLEU@100: 19.48 | AVG: 17.11\n","\n","\n","üèÜ Epoch 7 | ID2MAD BLEU@100: 14.91\n","\n","\n","üèÜ Epoch 7 | ID2MAD BLEU@100: 14.91 | MAD2ID BLEU@100: 20.72 | AVG: 17.81\n","\n","\n","üèÜ Epoch 8 | ID2MAD BLEU@100: 14.17\n","\n","\n","üèÜ Epoch 8 | ID2MAD BLEU@100: 14.17 | MAD2ID BLEU@100: 21.62 | AVG: 17.90\n","\n","\n","üèÜ Epoch 9 | ID2MAD BLEU@100: 14.96\n","\n","\n","üèÜ Epoch 9 | ID2MAD BLEU@100: 14.96 | MAD2ID BLEU@100: 20.42 | AVG: 17.69\n","\n","\n","üèÜ Epoch 10 | ID2MAD BLEU@100: 14.75\n","\n","\n","üèÜ Epoch 10 | ID2MAD BLEU@100: 14.75 | MAD2ID BLEU@100: 20.93 | AVG: 17.84\n","\n","\n","==============================\n","üìå RINGKASAN BLEU PER EPOCH (AVG)\n","==============================\n","Epoch 1: ID2MAD=15.75 | MAD2ID=21.33 | AVG=18.54\n","Epoch 2: ID2MAD=16.47 | MAD2ID=18.76 | AVG=17.61\n","Epoch 3: ID2MAD=12.50 | MAD2ID=16.31 | AVG=14.40\n","Epoch 4: ID2MAD=15.13 | MAD2ID=18.61 | AVG=16.87\n","Epoch 5: ID2MAD=15.35 | MAD2ID=19.74 | AVG=17.55\n","Epoch 6: ID2MAD=14.73 | MAD2ID=19.48 | AVG=17.11\n","Epoch 7: ID2MAD=14.91 | MAD2ID=20.72 | AVG=17.81\n","Epoch 8: ID2MAD=14.17 | MAD2ID=21.62 | AVG=17.90\n","Epoch 9: ID2MAD=14.96 | MAD2ID=20.42 | AVG=17.69\n","Epoch 10: ID2MAD=14.75 | MAD2ID=20.93 | AVG=17.84\n","------------------------------\n","‚úÖ Overall AVG BLEU across epochs: 17.33\n","==============================\n","\n","‚úÖ Model disimpan ke: ./indobenchmark-indobart-v2\n","‚ÑπÔ∏è Tokenizer tidak disimpan (pakai tokenizer bawaan indobenchmark/indobart-v2).\n","Best checkpoint: None\n","Best metric: None\n"]}],"execution_count":null},{"cell_type":"code","source":"try:\n    tokenizer.save_pretrained(OUTPUT_DIR)\nexcept Exception as e:\n    print(\"Tokenizer tidak bisa disave dengan save_pretrained (aman di-skip):\", repr(e))","metadata":{"execution":{"iopub.execute_input":"2025-12-14T12:35:27.341335Z","iopub.status.busy":"2025-12-14T12:35:27.341094Z","iopub.status.idle":"2025-12-14T12:35:27.344885Z","shell.execute_reply":"2025-12-14T12:35:27.344209Z","shell.execute_reply.started":"2025-12-14T12:35:27.341316Z"},"trusted":true},"outputs":[],"execution_count":57},{"cell_type":"code","source":"# ======================\n# CUSTOM EVALUATION (PRINT + BLEU + CONTOH)\n# ======================\n\nfrom tqdm.auto import tqdm\nimport sacrebleu\nimport torch\n\nprint(\"üìÇ Memuat model...\")\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = trainer.model.to(device)\nmodel.eval()\n\nTEST_PATH = \"/kaggle/input/nusaxdata/test (1).csv\"  \n\nprint(f\"üìÇ Membaca data tes: {TEST_PATH}\")\ntest_df = pd.read_csv(TEST_PATH)\ntest_df = drop_unnamed_cols(test_df)\n\nid_col = guess_column(test_df, [\"ind\", \"id\", \"indo\", \"indonesian\"])\nmad_col = guess_column(test_df, [\"mad\", \"madurese\", \"madura\"])\ntest_df = test_df[[id_col, mad_col]].rename(columns={id_col: \"id\", mad_col: \"mad\"})\n\ntest_df[\"id\"]  = test_df[\"id\"].apply(clean_text)\ntest_df[\"mad\"] = test_df[\"mad\"].apply(clean_text)\n\nN = 100\ntest_df = test_df.head(N)\nprint(f\"‚úÖ Menguji pada {len(test_df)} kalimat pertama.\")\nprint(\"üöÄ Mulai Menerjemahkan...\")\n\nsources = [\"translate Indonesian to Madurese: \" + x for x in test_df[\"id\"].tolist()]\nrefs    = test_df[\"mad\"].tolist()\n\npreds = []\nbatch_size = 8\n\nfor i in tqdm(range(0, len(sources), batch_size)):\n    batch = sources[i:i+batch_size]\n    enc = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n    enc = {k: v.to(device) for k, v in enc.items()}\n    with torch.no_grad():\n        out = model.generate(**enc, max_new_tokens=128, num_beams=4)\n\n    # >>> FIX DI SINI\n    preds.extend([tokenizer.decode(o, skip_special_tokens=True) for o in out])\n\nbleu = sacrebleu.corpus_bleu(preds, [refs]).score\n\nprint(\"\\n==============================\")\nprint(f\"üèÜ REAL BLEU SCORE: {bleu:.2f}\")\nprint(\"==============================\\n\")\n\nprint(\"üîç 5 CONTOH HASIL:\")\nfor i in range(min(5, len(test_df))):\n    print(f\"üáÆüá© Indo  : {test_df.iloc[i]['id']}\")\n    print(f\"ü§ñ Model : {preds[i]}\")\n    print(f\"üîë Kunci : {refs[i]}\")\n    print(\"-\" * 20)\n","metadata":{"execution":{"iopub.execute_input":"2025-12-14T12:35:28.776560Z","iopub.status.busy":"2025-12-14T12:35:28.776043Z","iopub.status.idle":"2025-12-14T12:35:53.290492Z","shell.execute_reply":"2025-12-14T12:35:53.289625Z","shell.execute_reply.started":"2025-12-14T12:35:28.776535Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["üìÇ Memuat model...\n","üìÇ Membaca data tes: /kaggle/working/nusax/test.csv\n","‚úÖ Menguji pada 100 kalimat pertama.\n","üöÄ Mulai Menerjemahkan...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f6284f1f74b4bae8b55ec736ec59d96","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","==============================\n","üèÜ REAL BLEU SCORE: 15.50\n","==============================\n","\n","üîç 5 CONTOH HASIL:\n","üáÆüá© Indo  : Dekat dengan hotel saya menginap, hanya ditempuh jalan kaki, di sini banyak sekali pilihan makanannya, tempat yang luas, dan menyenangkan\n","ü§ñ Model :  parjelenan bik hotel engkok nginep, pera' ditempuh jelen kaki, e diye bennyak sarah pelean kakananna, kennengngan se leber, ben masenneng sarah. eman ongghu. ban kaso'on.'. bannya' sarah.', bennya'.''.''\n","üîë Kunci : Semmak bik hotel engkok nginep, pera' ejeleni ajelen soko, ediye bennyak sarah pelean kakananna, kenengngan se leber, ben masenneng\n","--------------------\n","üáÆüá© Indo  : Iya benar, dia sedang jaga warung.\n","ü§ñ Model :  iye bhender, engkok bik selaen jaga warung. bhenderre'. bhendinga'.\n","üîë Kunci : Iye bhender, rua ajege berung.\n","--------------------\n","üáÆüá© Indo  : Kangkungnya lumayan tapi kepiting saus padangnya mengecewakan kami dikasih kepiting yang kopong akhir kami tidak makan keptingnya dan dikembalikan.\n","ü§ñ Model :  kangkungnga pendhenan tape kepiting saus padangnga tak masenneng engkok bik selaen eberrik kepiting se kopong akhir engkok tak ngakan keptingnga ben ebhending.'.'\n","üîë Kunci : Kangkongnga pendhanan tape kopeteng saos padangnga ma kocaba, engko' bi' laenna e bharri' kopeteng se kopong akherra engko' bi' laenna ta' ngakan kopeteng ban e pabali.\n","--------------------\n","üáÆüá© Indo  : Bertempat di braga city walk yang satu gedung dengan aston dan fave hotel, tempat ini sangat nyaman buat kongkow-kongkow. Kopi campur teh yang baru pertama kali saya nikmati ternyata sangat enak, dipadu dengan telur setengah matang menjadi pendamping mengobrol bersama teman-teman. Area yang bebas merokok semakin mengasyikkan sambil menikmati pemandangan lalu lalang orang-orang yang keluar masuk mal ini.\n","ü§ñ Model :  taghi e braga city walk se settong gedung bik aston ben fave hotel, kennengngan riya nyaman ghebey apolkompol. kopi ghuring teh se bhuru pertama kale engkok nikmati bhegus sarah, e sampek bik telur setengah matang deddhi pendamping ngakan bik cakanca. area se bebas merokok saengghe amassa' sambi menikmati pangabesen seppe torcatoran abiteng-oreng se esadiye'eghi mal riya.. ekanca' aghebey masenneng ongghu. kenengngan se lerres onggh\n","üîë Kunci : Kenengnganna e braga city walk se settong gheddung bik aston ben fave hotel, kenengngan riya nyaman sarah ghebey tor-catoran. Biddheng campor teh se ludhulluna engkok nginum bhuktena cek nyamanna, ecampor bik tellor massak saparo deddhi pendamping tor-catoran bik ca-kanca. Kenengngan se olle arokok tambe masenneng sambi menikmati pangabesen oreng-oreng se aje'genjir kaluar masok mal riya.\n","--------------------\n","üáÆüá© Indo  : Gianyar terima bantuan sosial 2018 sebesar rp 44, 9 miliar\n","ü§ñ Model :  kabbhi bantuan sosial 2018 ongghu rp 44, 9 miliar. gianyar bhegus sarah.\n","üîë Kunci : Gianyar tarema bhantoan sosial 2018 saraja rp 44,9 miliar.\n","--------------------\n"]}],"execution_count":null},{"cell_type":"code","source":"import torch\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = trainer.model.to(device)\nmodel.eval()\n\nMAX_LEN_SRC = 128\nMAX_NEW_TOK = 128\n\ndef generate_batch(sources, batch_size=8):\n    preds = []\n    for i in range(0, len(sources), batch_size):\n        batch = sources[i:i+batch_size]\n        enc = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LEN_SRC)\n        enc = {k: v.to(device) for k, v in enc.items()}\n        with torch.no_grad():\n            out = model.generate(**enc, max_new_tokens=MAX_NEW_TOK, num_beams=4)\n\n        # >>> CHANGED: jangan batch_decode untuk IndoNLGTokenizer\n        preds.extend([tokenizer.decode(o, skip_special_tokens=True) for o in out])\n\n    return preds\n\nimport evaluate\nbleu = evaluate.load(\"sacrebleu\")\nrouge = evaluate.load(\"rouge\")\n\ndef score(preds, refs):\n    b = bleu.compute(predictions=preds, references=[[r] for r in refs])[\"score\"]\n    r = rouge.compute(predictions=preds, references=refs)\n    return {\"BLEU\": b, \"ROUGE-1\": r[\"rouge1\"], \"ROUGE-L\": r[\"rougeL\"]}\n\n# VALID\nsrc_id2mad = [\"translate Indonesian to Madurese: \" + x for x in valid_mix[\"id\"].tolist()]\nref_id2mad = valid_mix[\"mad\"].tolist()\npred_id2mad = generate_batch(src_id2mad)\nprint(\"VALID ID ‚Üí MAD:\", score(pred_id2mad, ref_id2mad))\n\nsrc_mad2id = [\"translate Madurese to Indonesian: \" + x for x in valid_mix[\"mad\"].tolist()]\nref_mad2id = valid_mix[\"id\"].tolist()\npred_mad2id = generate_batch(src_mad2id)\nprint(\"VALID MAD ‚Üí ID:\", score(pred_mad2id, ref_mad2id))\n\n# TEST\nsrc_id2mad = [\"translate Indonesian to Madurese: \" + x for x in nusax_test[\"id\"].tolist()]\nref_id2mad = nusax_test[\"mad\"].tolist()\npred_id2mad = generate_batch(src_id2mad)\nprint(\"TEST ID ‚Üí MAD:\", score(pred_id2mad, ref_id2mad))\n\nsrc_mad2id = [\"translate Madurese to Indonesian: \" + x for x in nusax_test[\"mad\"].tolist()]\nref_mad2id = nusax_test[\"id\"].tolist()\npred_mad2id = generate_batch(src_mad2id)\nprint(\"TEST MAD ‚Üí ID:\", score(pred_mad2id, ref_mad2id))\n","metadata":{"execution":{"iopub.execute_input":"2025-12-14T12:36:02.542662Z","iopub.status.busy":"2025-12-14T12:36:02.542199Z","iopub.status.idle":"2025-12-14T12:39:19.702337Z","shell.execute_reply":"2025-12-14T12:39:19.701665Z","shell.execute_reply.started":"2025-12-14T12:36:02.542637Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["VALID ID ‚Üí MAD: {'BLEU': 14.746241869737535, 'ROUGE-1': 0.4462242276523025, 'ROUGE-L': 0.4331282451227373}\n","VALID MAD ‚Üí ID: {'BLEU': 20.93414376974587, 'ROUGE-1': 0.5262434375864424, 'ROUGE-L': 0.5129215980981093}\n","TEST ID ‚Üí MAD: {'BLEU': 15.713515275134364, 'ROUGE-1': 0.46672209513455976, 'ROUGE-L': 0.4532801193530669}\n","TEST MAD ‚Üí ID: {'BLEU': 22.071250626656674, 'ROUGE-1': 0.5451958332518148, 'ROUGE-L': 0.5312517830491592}\n"]}],"execution_count":null},{"cell_type":"code","source":"# ======================\n# CUSTOM EVALUATION (PRINT + BLEU + CONTOH) - MADURA -> INDONESIA\n# ======================\n\nfrom tqdm.auto import tqdm\nimport sacrebleu\nimport torch\nimport pandas as pd\n\nprint(\"üìÇ Memuat model...\")\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = trainer.model.to(device)\nmodel.eval()\n\nprint(f\"üìÇ Membaca data tes: {TEST_PATH}\")\ntest_df = pd.read_csv(TEST_PATH)\ntest_df = drop_unnamed_cols(test_df)\n\nid_col  = guess_column(test_df, [\"ind\", \"id\", \"indo\", \"indonesian\"])\nmad_col = guess_column(test_df, [\"mad\", \"madurese\", \"madura\"])\n\ntest_df = test_df[[id_col, mad_col]].rename(columns={id_col: \"id\", mad_col: \"mad\"})\n\ntest_df[\"id\"]  = test_df[\"id\"].apply(clean_text)\ntest_df[\"mad\"] = test_df[\"mad\"].apply(clean_text)\n\nN = 100\ntest_df = test_df.head(N)\nprint(f\"‚úÖ Menguji pada {len(test_df)} kalimat pertama.\")\nprint(\"üöÄ Mulai Menerjemahkan...\")\n\nsources = [\"translate Madurese to Indonesian: \" + x for x in test_df[\"mad\"].tolist()]\nrefs    = test_df[\"id\"].tolist()\n\npreds = []\nbatch_size = 8\n\nfor i in tqdm(range(0, len(sources), batch_size)):\n    batch = sources[i:i+batch_size]\n    enc = tokenizer(\n        batch,\n        return_tensors=\"pt\",\n        padding=True,\n        truncation=True,\n        max_length=128\n    )\n    enc = {k: v.to(device) for k, v in enc.items()}\n\n    with torch.no_grad():\n        out = model.generate(\n            **enc,\n            max_new_tokens=128,\n            num_beams=4\n        )\n\n    # ‚úÖ FIX: IndoNLGTokenizer tidak kompatibel dengan batch_decode (clean_up_tokenization_spaces)\n    preds.extend([tokenizer.decode(o, skip_special_tokens=True) for o in out])\n\nbleu = sacrebleu.corpus_bleu(preds, [refs]).score\n\nprint(\"\\n==============================\")\nprint(f\"üèÜ REAL BLEU SCORE (MAD‚ÜíID): {bleu:.2f}\")\nprint(\"==============================\\n\")\n\nprint(\"üîç 5 CONTOH HASIL:\")\nfor i in range(min(5, len(test_df))):\n    print(f\"üü´ Madura : {test_df.iloc[i]['mad']}\")\n    print(f\"ü§ñ Model  : {preds[i]}\")\n    print(f\"üîë Kunci  : {refs[i]}\")\n    print(\"-\" * 20)\n","metadata":{"execution":{"iopub.execute_input":"2025-12-14T12:41:00.700514Z","iopub.status.busy":"2025-12-14T12:41:00.700207Z","iopub.status.idle":"2025-12-14T12:41:16.181533Z","shell.execute_reply":"2025-12-14T12:41:16.180640Z","shell.execute_reply.started":"2025-12-14T12:41:00.700492Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["üìÇ Memuat model...\n","üìÇ Membaca data tes: /kaggle/working/nusax/test.csv\n","‚úÖ Menguji pada 100 kalimat pertama.\n","üöÄ Mulai Menerjemahkan...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa01a4f87370467091993dc385ff7902","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","==============================\n","üèÜ REAL BLEU SCORE (MAD‚ÜíID): 23.21\n","==============================\n","\n","üîç 5 CONTOH HASIL:\n","üü´ Madura : Semmak bik hotel engkok nginep, pera' ejeleni ajelen soko, ediye bennyak sarah pelean kakananna, kenengngan se leber, ben masenneng\n","ü§ñ Model  :  semmak dengan hotel saya menginap, hanya dengan alas daun, di sini banyak sekali pilihan makanannya, tempat yang luas, dan sangat menyenangkan. sangat direkomendasikan.\n","üîë Kunci  : Dekat dengan hotel saya menginap, hanya ditempuh jalan kaki, di sini banyak sekali pilihan makanannya, tempat yang luas, dan menyenangkan\n","--------------------\n","üü´ Madura : Iye bhender, rua ajege berung.\n","ü§ñ Model  :  iye bhender, itu ayam berung. hehehe.\n","üîë Kunci  : Iya benar, dia sedang jaga warung.\n","--------------------\n","üü´ Madura : Kangkongnga pendhanan tape kopeteng saos padangnga ma kocaba, engko' bi' laenna e bharri' kopeteng se kopong akherra engko' bi' laenna ta' ngakan kopeteng ban e pabali.\n","ü§ñ Model  :  makanannya lumayan tapi nasi goreng saos padangnya mengecewakan, saya juga di pesan nasi goreng yang kopongnya saya tidak pernah makan nasi dan di rumah. tidak ada pilihan lain. kurang rekomendasi.\n","üîë Kunci  : Kangkungnya lumayan tapi kepiting saus padangnya mengecewakan kami dikasih kepiting yang kopong akhir kami tidak makan keptingnya dan dikembalikan.\n","--------------------\n","üü´ Madura : Kenengnganna e braga city walk se settong gheddung bik aston ben fave hotel, kenengngan riya nyaman sarah ghebey tor-catoran. Biddheng campor teh se ludhulluna engkok nginum bhuktena cek nyamanna, ecampor bik tellor massak saparo deddhi pendamping tor-catoran bik ca-kanca. Kenengngan se olle arokok tambe masenneng sambi menikmati pangabesen oreng-oreng se aje'genjir kaluar masok mal riya.\n","ü§ñ Model  :  tempatnya di braga city walk yang satu lagi dekat dengan aston dan fave hotel, tempat ini sangat nyaman untuk mengobrol. kopi yang disajikan pun sangat enak, ecampor dengan tellor air terjun saparo sebagai pendamping mengobrol dengan teman-teman. tempat yang dapat menikmati pemandangan sungai kecil yang menjadi pemandangan di mal ini. lokasi yang sangat cocok untuk menikmati suasana pedesaan yang hijau. sangat direkomendasikan. tidak perlu pikir dua kali jika mau ke tempat ini lagi.:::.\n","üîë Kunci  : Bertempat di braga city walk yang satu gedung dengan aston dan fave hotel, tempat ini sangat nyaman buat kongkow-kongkow. Kopi campur teh yang baru pertama kali saya nikmati ternyata sangat enak, dipadu dengan telur setengah matang menjadi pendamping mengobrol bersama teman-teman. Area yang bebas merokok semakin mengasyikkan sambil menikmati pemandangan lalu lalang orang-orang yang keluar masuk mal ini.\n","--------------------\n","üü´ Madura : Gianyar tarema bhantoan sosial 2018 saraja rp 44,9 miliar.\n","ü§ñ Model  :  gianyar ikuti bhantoan sosial 2018 saraja rp 44,9 miliar. - gianyar\n","üîë Kunci  : Gianyar terima bantuan sosial 2018 sebesar rp 44, 9 miliar\n","--------------------\n"]}],"execution_count":62},{"cell_type":"code","source":"import torch\nimport evaluate\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n# Ensure clean_text and fix_mojibake are available\n# If you encounter a NameError for clean_text or fix_mojibake, please run the preprocessing cells (tS4yoEHnq713) first.\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Load the best model and tokenizer from the final checkpoint\n# MODEL_DIR is defined in previous cells and points to the best checkpoint.\n# Assuming tokenizer and model from cell uzoYf3xlOElU are the desired ones.\n# If model and tokenizer are not defined, please re-run cell uzoYf3xlOElU.\nif 'model' not in globals() or 'tokenizer' not in globals():\n    print(\"Loading model and tokenizer from MODEL_DIR...\")\n    MODEL_DIR = \"./cendol_mt5_id_mad/checkpoint-2500/checkpoint-3750\"\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n    model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_DIR).to(device)\nmodel.eval()\n\nMAX_LEN_SRC = 128\nMAX_NEW_TOK = 128\n\nrouge_metric = evaluate.load(\"rouge\")\nbleu_metric = evaluate.load(\"sacrebleu\") # Load BLEU metric\n\ndef generate_single_text(raw_text: str, direction: str, current_model, current_tokenizer):\n    if 'clean_text' not in globals():\n        raise NameError(\"clean_text function is not defined. Please run cell tS4yoEHnq713.\")\n\n    cleaned_text = clean_text(raw_text) # Apply clean_text to the actual content\n    if direction == \"id2mad\":\n        src_prompt = \"translate Indonesian to Madurese: \" + cleaned_text\n    elif direction == \"mad2id\":\n        src_prompt = \"translate Madurese to Indonesian: \" + cleaned_text\n    else:\n        raise ValueError(\"Invalid direction for translation.\")\n\n    enc = current_tokenizer(src_prompt, return_tensors=\"pt\", truncation=True, max_length=MAX_LEN_SRC).to(current_model.device)\n    with torch.no_grad():\n        out = current_model.generate(**enc, max_new_tokens=MAX_NEW_TOK)\n    return current_tokenizer.decode(out[0], skip_special_tokens=True)\n\ndef score_single_translation(prediction: str, reference: str):\n    # Calculate ROUGE scores\n    rouge_scores = rouge_metric.compute(predictions=[prediction], references=[reference])\n    # Calculate BLEU score\n    bleu_score = bleu_metric.compute(predictions=[prediction], references=[[reference]])[\"score\"]\n    return {\n        \"BLEU\": bleu_score,\n        \"ROUGE-1\": rouge_scores[\"rouge1\"],\n        \"ROUGE-L\": rouge_scores[\"rougeL\"]\n    }\n\nprint(\"\\n--- Analysis of Test Data Translations ---\")\n\n# Assuming test_clean DataFrame is available from earlier cells\nif 'test_clean' not in globals():\n    print(\"Error: 'test_clean' DataFrame not found. Please ensure preprocessing cells are run.\")\nelse:\n    print(\"\\nIndonesian -> Madurese Translations:\")\n    for i, row in nusax_test.head(30).iterrows(): # Limit to 30 samples\n        id_text = row[\"id\"]\n        mad_ref = row[\"mad\"]\n\n        mad_pred = generate_single_text(id_text, \"id2mad\", model, tokenizer)\n        scores = score_single_translation(mad_pred, mad_ref)\n\n        print(f\"--- Sample {i+1} (ID -> MAD) ---\")\n        print(f\"Source (ID):     {id_text}\")\n        print(f\"Reference (MAD): {mad_ref}\")\n        print(f\"Prediction (MAD):{mad_pred}\")\n        print(f\"BLEU Score:      {scores['BLEU']:.4f}\")\n        print(f\"ROUGE-1 Score:   {scores['ROUGE-1']:.4f}\")\n        print(f\"ROUGE-L Score:   {scores['ROUGE-L']:.4f}\\n\")\n\n    print(\"\\nMadurese -> Indonesian Translations:\")\n    for i, row in nusax_test.head(30).iterrows(): # Limit to 30 samples\n        mad_text = row[\"mad\"]\n        id_ref = row[\"id\"]\n\n        id_pred = generate_single_text(mad_text, \"mad2id\", model, tokenizer)\n        scores = score_single_translation(id_pred, id_ref)\n\n        print(f\"--- Sample {i+1} (MAD -> ID) ---\")\n        print(f\"Source (MAD):     {mad_text}\")\n        print(f\"Reference (ID): {id_ref}\")\n        print(f\"Prediction (ID):{id_pred}\")\n        print(f\"BLEU Score:      {scores['BLEU']:.4f}\")\n        print(f\"ROUGE-1 Score:   {scores['ROUGE-1']:.4f}\")\n        print(f\"ROUGE-L Score:   {scores['ROUGE-L']:.4f}\\n\")","metadata":{"execution":{"iopub.execute_input":"2025-12-14T12:41:50.030996Z","iopub.status.busy":"2025-12-14T12:41:50.030695Z","iopub.status.idle":"2025-12-14T12:42:39.025324Z","shell.execute_reply":"2025-12-14T12:42:39.024563Z","shell.execute_reply.started":"2025-12-14T12:41:50.030974Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--- Analysis of Test Data Translations ---\n","\n","Indonesian -> Madurese Translations:\n","--- Sample 1 (ID -> MAD) ---\n","Source (ID):     Dekat dengan hotel saya menginap, hanya ditempuh jalan kaki, di sini banyak sekali pilihan makanannya, tempat yang luas, dan menyenangkan\n","Reference (MAD): Semmak bik hotel engkok nginep, pera' ejeleni ajelen soko, ediye bennyak sarah pelean kakananna, kenengngan se leber, ben masenneng\n","Prediction (MAD): parjelenan bik hotel engkok nginep, pera' ditempuh jelen kaki, e diye bennyak sarah pelean kakananna, kennengngan se leber, ben masenneng sarah. eman ongghu. ban kaso'on.'. bannya' sarah.', bennya'.''.''\n","BLEU Score:      26.2503\n","ROUGE-1 Score:   0.5417\n","ROUGE-L Score:   0.5417\n","\n","--- Sample 2 (ID -> MAD) ---\n","Source (ID):     Iya benar, dia sedang jaga warung.\n","Reference (MAD): Iye bhender, rua ajege berung.\n","Prediction (MAD): iye bhender, engkok bik selaen jaga warung. bhenderre'. bhendinga'.\n","BLEU Score:      6.8372\n","ROUGE-1 Score:   0.2857\n","ROUGE-L Score:   0.2857\n","\n","--- Sample 3 (ID -> MAD) ---\n","Source (ID):     Kangkungnya lumayan tapi kepiting saus padangnya mengecewakan kami dikasih kepiting yang kopong akhir kami tidak makan keptingnya dan dikembalikan.\n","Reference (MAD): Kangkongnga pendhanan tape kopeteng saos padangnga ma kocaba, engko' bi' laenna e bharri' kopeteng se kopong akherra engko' bi' laenna ta' ngakan kopeteng ban e pabali.\n","Prediction (MAD): kangkungnga pendhenan tape kepiting saus padangnga tak masenneng engkok bik selaen eberrik kepiting se kopong akhir engkok tak ngakan keptingnga ben ebhending.'.'\n","BLEU Score:      3.5208\n","ROUGE-1 Score:   0.2083\n","ROUGE-L Score:   0.2083\n","\n","--- Sample 4 (ID -> MAD) ---\n","Source (ID):     Bertempat di braga city walk yang satu gedung dengan aston dan fave hotel, tempat ini sangat nyaman buat kongkow-kongkow. Kopi campur teh yang baru pertama kali saya nikmati ternyata sangat enak, dipadu dengan telur setengah matang menjadi pendamping mengobrol bersama teman-teman. Area yang bebas merokok semakin mengasyikkan sambil menikmati pemandangan lalu lalang orang-orang yang keluar masuk mal ini.\n","Reference (MAD): Kenengnganna e braga city walk se settong gheddung bik aston ben fave hotel, kenengngan riya nyaman sarah ghebey tor-catoran. Biddheng campor teh se ludhulluna engkok nginum bhuktena cek nyamanna, ecampor bik tellor massak saparo deddhi pendamping tor-catoran bik ca-kanca. Kenengngan se olle arokok tambe masenneng sambi menikmati pangabesen oreng-oreng se aje'genjir kaluar masok mal riya.\n","Prediction (MAD): taghi e braga city walk se settong gedung bik aston ben fave hotel, kennengngan riya nyaman ghebey apolkompol. kopi ghuring teh se bhuru pertama kale engkok nikmati bhegus sarah, e sampek bik telur setengah matang deddhi pendamping ngakan bik cakanca. area se bebas merokok saengghe amassa' sambi menikmati pangabesen seppe torcatoran abiteng-oreng se esadiye'eghi mal riya.. ekanca' aghebey masenneng ongghu. kenengngan se lerres onggh\n","BLEU Score:      19.9204\n","ROUGE-1 Score:   0.5079\n","ROUGE-L Score:   0.4603\n","\n","--- Sample 5 (ID -> MAD) ---\n","Source (ID):     Gianyar terima bantuan sosial 2018 sebesar rp 44, 9 miliar\n","Reference (MAD): Gianyar tarema bhantoan sosial 2018 saraja rp 44,9 miliar.\n","Prediction (MAD): kabbhi bantuan sosial 2018 ongghu rp 44, 9 miliar. gianyar bhegus sarah.\n","BLEU Score:      7.8594\n","ROUGE-1 Score:   0.6364\n","ROUGE-L Score:   0.5455\n","\n","--- Sample 6 (ID -> MAD) ---\n","Source (ID):     Ini salah satu contoh generasi yang tidak berguna. Bukan malah bermanfaat untuk bangsa tapi malah jadi sesuatu yang berbahaya bagi bangsa! Mantap jerat saja pakai uu ite\n","Reference (MAD): Ariya salah settong conto toronan se tak aghuna. Benni jen aberri' manfaat ghebey bangsa tape jen deddhi bahaya ka bangsa! Mantap tangkep bhei angghuy uu ite\n","Prediction (MAD): ariya sala settong contoh generasi se tak aghuna. banni malah ghebey bangsa tape malah deddhi palappana se ghabay bhegus ka bangsa! mantap jerat bhei ngangghuy uu ite kaduwe'eghi uu ite. bhekal kiya aghebey uu ite! bhehusse'egusse.com__.\n","BLEU Score:      10.7638\n","ROUGE-1 Score:   0.4615\n","ROUGE-L Score:   0.4615\n","\n","--- Sample 7 (ID -> MAD) ---\n","Source (ID):     Sore sahabat, saat ini sedang dilakukan pemeliharaan sehingga aplikasi tidak dapat diakses.\n","Reference (MAD): Sore kanca, bekto satiya ghik e lakonin pemeliharaan saengghe aplikasi tak bisa eyangghuy.\n","Prediction (MAD): sore sahabat, satiya riya ghik esare pemeliharaan saengghe aplikasi tak olle epateppa'. amargha ba'na. . .\n","BLEU Score:      15.0717\n","ROUGE-1 Score:   0.5000\n","ROUGE-L Score:   0.5000\n","\n","--- Sample 8 (ID -> MAD) ---\n","Source (ID):     Memang lemah kita ini aku juga penakut sebenarnya\n","Reference (MAD): Jhet tak kuat engkok bik bekna riya engkok tako'an kiya saongghuna\n","Prediction (MAD): jhet lemah enje' engkok riya engkok kiya penakut sabbhenna sajen se baghusse.hei'.te'eghi jhek satiya.huwa jhek.hujhu.huu.hu'.huah.huuh.hueh.hu__.hu .hu.'u'.u.u'u. tada'u bi'u engkok.hu jhek engkok penakut.hu.uw.huik.hu ghik.uwik engkok tada' bi' kiya.hur.hu e tada'.hurik.\n","BLEU Score:      1.0713\n","ROUGE-1 Score:   0.1471\n","ROUGE-L Score:   0.1471\n","\n","--- Sample 9 (ID -> MAD) ---\n","Source (ID):     Terakhir ke hanamasa harganya 120 ribu / orang. Tapi puasnya lebih dari itu. Bisa ambil makanan sepuasnya, tapi rasa tidak mengecewakan, pintar-pintar kita saja meracik sendiri. Kalau penggemar daging sapi pasti suka ke sini\n","Reference (MAD): Terakhir ka hanamasa regghena 120 ebhu per oreng. Tape puassa lebbi deri rua. Bisa ngalak kakanan sapuassa, tape rassana tak mengecewakan, penter-penter kita beih se aracik thibik. Mun penggemar dheghing sape paste senneng ka dinnak.\n","Prediction (MAD): paleng ka hanamasa regghena 120 ebu / oreng. tape puasana lebbi deri rua. bisa olle kakanan sapuassa, tape rassana tak makacewa, pintar-pintar engkok bik se laen bhei meracik sendiri. mun penggemar daging sapi paste senneng ka diye'eghi. mun se penggemar daging ajem pasti suka ka dia'.\n","BLEU Score:      21.5369\n","ROUGE-1 Score:   0.5060\n","ROUGE-L Score:   0.5060\n","\n","--- Sample 10 (ID -> MAD) ---\n","Source (ID):     Untuk menuju ke the peak memang terasa sangat jauh dari pusat kota bandung, dan aksesnya yang agak membingungkan dan jalan kecil berkelok-kelok. Namun anda mungkin tidak akan tersesat karena hampir di tiap belokan ada signage menuju ke the peak. Tempatnya sangat bagus untuk anda yang mencari suasana malam romantis, dengan pemandangan malam kota yang menakjubkan.\n","Reference (MAD): Ghabay entar ka the peak jhat karassa jhau ongghu dari pusat kotta bandung ban aksessa se ba' maposang ban jalan kini' lu'-bilu'. Nangeng ba'na mase ta' kera nyasar amargha e sabban bilughan bada tandha nojjhu ka the peak. Kennenganna baghus ongghu ghabay ba'na se nyare pangabasan malem romantis, bik pamandhangan malem kotta se baghus ongghu.\n","Prediction (MAD): ghebey entar ka the peak jhet rassana sarah deri pusat kotta bandung, ben aksesnya se bek membingungkan ben jelenna kenik ngirem-kendem. keng bekna se paleng tak kera tak kera abeli polana hampir e sabbhen belokan bede signage ka the leak. kenengnganna cek bhegus sarah ghebeyen bekto se nyare suasana malem romantis, bik pangabesen malem kotta se lebur. keng kaso'on ongghu. kennenganna sarah ghegghuen sarah ghellu. ghellek ghellesse\n","BLEU Score:      10.9013\n","ROUGE-1 Score:   0.3465\n","ROUGE-L Score:   0.3307\n","\n","--- Sample 11 (ID -> MAD) ---\n","Source (ID):     Kebun raya bogor bisa dijadikan salah satu tujuan destinasi wisata\n","Reference (MAD): kebun raya bogor bisa epadeddhi salah settong tojjhuen kennengngan wisata\n","Prediction (MAD): kebun raya bogor bisa edetengngi salah settong tujuan destinasi wisata. bhegusse sarah.\n","BLEU Score:      21.9728\n","ROUGE-1 Score:   0.6364\n","ROUGE-L Score:   0.6364\n","\n","--- Sample 12 (ID -> MAD) ---\n","Source (ID):     The peak berlokasi di dekat lembang, dataran tinggi di bandung yang sejuk dan lokasi yang sangat baik namun jalan untuk mencapai tempat ini sangat berkelok disertai tikungan tajam nan curam, tidak disarankan untuk berkendara saat hujan dan malam hari. Di the peak terdapat restoran dengan pemandangan kota bandung yang indah dari perbukitan, harga makanan yang sangat mahal dan sangat tidak sesuai.\n","Reference (MAD): The peak kenengnganna bede e semmakna lembang, dataran tengghi e bandung se cellep ben kenengngan se bhegus sarah tape jelen ghebey entar ka kenengngan riya akelok sarah ben bhilughen tajhem ben nujjhek, tak esarannaghi ghebey nyetir bekto ojhen ben malem are. E the peak bede restoran bik pangabesen kotta bandung se lebur deri perbukitan, regghe kakanan se larang sarah ben tak cocok sarah.\n","Prediction (MAD): the peak bede e semma' lembang, dataran tengghi e bandung se cellep ben kennengngan se bhegus sarah tape jelenna ghebey mencapai kenengngan riya cek santakna torcatoran nan curam, tak esadiye'eghi ghente bekto ojhen ben malem are. e the peak ngennengngi restoran bik pangabesen kotta bandung se lebur deri jhengka, regghe kakanan se larang ben tak pade. se tak esarannaghi sarah. tak masenneng sarah. sarah. ekakanna ongghu bik se laen endik sarah ben\n","BLEU Score:      36.9009\n","ROUGE-1 Score:   0.6912\n","ROUGE-L Score:   0.6324\n","\n","--- Sample 13 (ID -> MAD) ---\n","Source (ID):     Saya kapok menggunakan jasa lion air\n","Reference (MAD): Engkok jherre angghuy jasa lion air\n","Prediction (MAD): engkok takerjhet angghuy jasa lion air. bhegus sarah.\n","BLEU Score:      26.2691\n","ROUGE-1 Score:   0.7143\n","ROUGE-L Score:   0.7143\n","\n","--- Sample 14 (ID -> MAD) ---\n","Source (ID):     Banyak hal yang dapat kita lakukan untuk mengisi waktu luang.\n","Reference (MAD): Bennyak hal se kaolle engkok bik bekna lakoni ghebey ngesse bekto luang.\n","Prediction (MAD): bannya' hal se olle engko' bi' laenna ghebey bekto luang. bhideh bik laenna.\n","BLEU Score:      13.3802\n","ROUGE-1 Score:   0.4800\n","ROUGE-L Score:   0.4000\n","\n","--- Sample 15 (ID -> MAD) ---\n","Source (ID):     Semakin apatis melaporkan hal-hal seperti ini. Karena sampai minggu lalu masih tetap belum dikerjakan. Hanya janji-janji terus.\n","Reference (MAD): Sajen apatis alaporraghi hal-hal mara riya. Polana sampe' minggu beerik ghik pagghun tak elakoni. Pera' jenji-jenji terros.\n","Prediction (MAD): sajen apatis narema hal-hal riya. polana sampe' minggu dhujen ghik pagghun ghik ghik belum ebhending. pera' janji-janji terro. ghik lambe'en ghitak ghik. nangengnganna ghik-ngompol terro torcatoran...\n","BLEU Score:      4.4205\n","ROUGE-1 Score:   0.4490\n","ROUGE-L Score:   0.4490\n","\n","--- Sample 16 (ID -> MAD) ---\n","Source (ID):     Harga selangit porsi seiprit tidak janji lagi saya datang untuk yang kedua kali. Masakannya tidak beda jauh sama ema saya dong!\n","Reference (MAD): Regghena cek larangngah taninganna sakunnik tak ajenji pole engkok deteng ghebey se dukalena. Massa'anna tak bhide jeuh bik Emakna engkok dong!\n","Prediction (MAD): regghena selangit porsi seiprit tak janji la engkok deteng ghebey se settong mare. massa'anna tak bhide jeu bi' ema engkok dong! dong!!.!.ngaghi bik se laen. palappana tada'. mabhungare.selengkapnya\n","BLEU Score:      9.9618\n","ROUGE-1 Score:   0.4906\n","ROUGE-L Score:   0.4528\n","\n","--- Sample 17 (ID -> MAD) ---\n","Source (ID):     Baru dan tersedia, 5 sekat makan siang kotak kotak makan yooyee kotak bekal anti bocor 590\n","Reference (MAD): Anyar ben la bede, lema' sekat ngakan aben tak-kotak ngakan yooyee kotak sangu se tak mabhucor 590\n","Prediction (MAD): bhuru ben tersedia, 5 sekat ngakan siang kotak kotak makan yooyee kotak bekal anti bocor 590 ebu. 2018. 0.00.00\n","BLEU Score:      5.6189\n","ROUGE-1 Score:   0.3590\n","ROUGE-L Score:   0.3590\n","\n","--- Sample 18 (ID -> MAD) ---\n","Source (ID):     Tidak mengerti ya kenapa resto ini menduduki peringkat 12 dari 1800an resto yang ada di jakarta. Harga mahal! Lokasi tersembunyi, dan rasa makanan biasa saja. Jangan terlalu percaya sama review yang menyesatkanlah.\n","Reference (MAD): Tak ngarte ye arapa resto riya ngatoju'i peringkat 12 deri 1800 an resto se bede e jakarta. Regghe larang! lokasina nyelket ngitek, ben rassa kakananna biasa bhei. Jhek pate parcaje ka tinjauan se aghebey kalero lah.\n","Prediction (MAD): tak parcaje ye arapa resto riya menduduki peringkat 12 deri 1800an resto se bede e jakarta. regghe larang! kennengnganna keddhe', ben rassa kakanan biasa bhei. jhek pate percaya padena review se menyesatkanlah. bhekal ongghu' bi' laenna. loppa jhek loppa bi'na.\n","BLEU Score:      23.6975\n","ROUGE-1 Score:   0.5897\n","ROUGE-L Score:   0.5641\n","\n","--- Sample 19 (ID -> MAD) ---\n","Source (ID):     Ledakan dalam aksi protes di afghanistan tewaskan 68 orang\n","Reference (MAD): Leddhu'en delem aksi protes e afghanistan mamate 68 oreng\n","Prediction (MAD): parjelenan delem aksi protes e afghanistan tewaskan 68 oreng se.\n","BLEU Score:      40.3528\n","ROUGE-1 Score:   0.7000\n","ROUGE-L Score:   0.7000\n","\n","--- Sample 20 (ID -> MAD) ---\n","Source (ID):     Saya berkunjung ke restoran itu bersama dengan teman saya. Teman saya kebanyakan terkejut melihat pemandangannya yang sangat indah di malam hari. Saya berkesempatan mencoba steak impornya, sangat enak apalagi sausnya. Mmm yummi. Kalau ada kesempatan saya ingin berkunjung lagi ke sana.\n","Reference (MAD): Engkok entar ka restoran rua bik kancana engkok. Kancana engkok kabennya'an tagherjet ngabes pangabesenna se lebur sarah e malem are. Engkok endik kasempatan nyoba steak imporra, nyaman sarah apa pole saossa. Mmm yummi. Mun bede kasempatan engkok terro entara pole ka dissa'.\n","Prediction (MAD): engkok entar ka restoran rua abharang bik cakanca engkok. kanca engkok kabbhi terkejut ngabes pangabesen se cek leburre e malem are. engkok arassa nyoba steak impornga, nyaman sarah apolkompolna. mmm yummi. mun bede kesempatan engkok terro entar pole ka dissa'. mun endik kasennengnganna engkok ingin entar pole de'enje. ghikennengngennengngi pole ka ekanca'. eman ongghu. deddhi sarah. mun kennengngan engkok bit-abiteh\n","BLEU Score:      14.6296\n","ROUGE-1 Score:   0.5714\n","ROUGE-L Score:   0.5143\n","\n","--- Sample 21 (ID -> MAD) ---\n","Source (ID):     Akses menuju dusun bambu bisa ditempuh kira-kira dalam waktu 1 - 2 jam menggunakan mobil pribadi. Berkunjung ke dusun bambu diusahakan saat petang hari karena kita dapat melihat jelas pemandangan yang ada dan waktu yang pas untuk makan malam.\n","Reference (MAD): Jelen nujjhu ka dusun perreng bisa ejeleni rakera delem bekto 1-2 jam angghuy mobil dhibik. Entar ka dusun perreng usaha'aghi bekto compet are polana engkok bik bekna bisa ngabes jelas pangabesen se bede ben bekto se pas ghebey ngakan malem.\n","Prediction (MAD): akses ka dusun bambu bisa eyangghuy kira-kira delem bekto 1-2 jam angghuy mobil pribadi. deteng ka jelenna'aghi bekto petang are polana engkok bik bekna olle ngabes jelas pangabesen se bede ben bekna se pas ghebey ngakan malem. otamana akses ka jelen ongghu bisa ebherse'e'e bekto.\n","BLEU Score:      41.2768\n","ROUGE-1 Score:   0.6957\n","ROUGE-L Score:   0.6304\n","\n","--- Sample 22 (ID -> MAD) ---\n","Source (ID):     Makanan oke sama seperti xo suki lainnya. Tetapi walaupun hari libur besar seperti lebaran ini bukan berarti senyumnya libur dan order minum, dan lain-lain harus order berkali-kali. Tolong di jaga kepuasan pelanggannya. Terima kasih.\n","Reference (MAD): Kakananna oke pade bik xo suki laenna. Tape tekka'na are prei raje padena tellasan riya benni pas misemma prei ben mesen enum, ben en-laen koduh mesen libelien. Tolong e jege kapuasan langghenanna. Kaso'on.\n","Prediction (MAD): kakanan oke pade padena xo suki laenna. tape walaupun are libur raje padena lebaran riya benni berarti senyumnya libur ben messen enoman, ben laen-laenna kodhu messen berkali-kali. tolong e jaga kapantenganna. kaso'on. terima kasih. katoju'en. jenjha. jenjen sarah. jenngenngenna. kennengnganna. jenjellassaghi. jensennih. jenje. jenji. jendhi. jenjana. jenlona. jenhalan. jendha. jenha\n","BLEU Score:      5.8172\n","ROUGE-1 Score:   0.4222\n","ROUGE-L Score:   0.4000\n","\n","--- Sample 23 (ID -> MAD) ---\n","Source (ID):     Restoran ini adalah sebuah destinasi kuliner yang wajib dikunjungi bila ke bandung. Selain makanan yang sangat memanjakan lidah makanan sunda, restoran ini juga dibangun dengan konsep makan santai di dalam saung yang dikelilingi alam hutan dan pegunungan yang dihias pepohonan rindang dan dihibur oleh gemericik air sungai sehingga menawarkan pengalaman kuliner yang teramat mengesankan. Harus dicoba bagi siapapun yang ke bandung.\n","Reference (MAD): Restoran riya tamasok kenengngan tojjhuen kuliner se wejib e detengi mun ka bandung. Salaen kakanan se manjaagi jhile kakanan sunda, restoran riya e bangun bik konsep ngakan santai e delem saung se ekalelengi alam alas ben ghunung se ehias papohonan rindang ben e hibur bik suarana aeng songai deddhina mataber aberrik pengalaman kuliner se masenneng sarah. Kodhu e cobak begi sapa'a bhei se ka bandung.\n","Prediction (MAD): restoran riya iye rua settong destinasi kuliner se kodhu edetengngi mun ka bandung. salaen kakanan se cek aghebey lidah kakanan sunda, restoran riya kiya dibangun bik konsep ngakan santai e delem saengghe alam panghunungan ben ebhendingngaghi bik gemericik dhemar-dhemar se dheddiye'eghi pengalaman kuliner se cek bhegusse. kodhuna e coba ghebey oreng se ke bandung. kodhu e sarannaghi bik bekna se entar bandung. selaen ongghu' bi' laenna.\n","BLEU Score:      19.3591\n","ROUGE-1 Score:   0.4925\n","ROUGE-L Score:   0.4478\n","\n","--- Sample 24 (ID -> MAD) ---\n","Source (ID):     Kembali mengaktifkan paket data indosat karena dapat akses youtube unlimited.\n","Reference (MAD): Ngaktiffeghi pole paket data indosat polana olle akses youtube tanpa betes.\n","Prediction (MAD): kembali nyobak paket data indosat polana olle akses youtube unlimited. bhuru satiya. maddha'.\n","BLEU Score:      38.5032\n","ROUGE-1 Score:   0.5833\n","ROUGE-L Score:   0.5833\n","\n","--- Sample 25 (ID -> MAD) ---\n","Source (ID):     Saya baru saja bertemu teman saya yang bekerja di trans tv\n","Reference (MAD): Engkok bhuru bhei katemmun kanca engkok se alako e trans tv\n","Prediction (MAD): engkok bhuru bhei numpa' ka cakanca engkok se alako e trans tv. bhuktena.\n","BLEU Score:      36.4141\n","ROUGE-1 Score:   0.7500\n","ROUGE-L Score:   0.7500\n","\n","--- Sample 26 (ID -> MAD) ---\n","Source (ID):     Rumah makan di jalan anggrek ini memiliki keistimewaan jenis seafood yang beragam dan ada yang masih hidup untuk dipilih dan dimasak saat itu juga. Berbagai jenis masakan dapat dipilih dan waktu tunggu yang singkat membuat kita tidak terlalu lama kelaparan menunggu. Menu kerapu kukusnya sangat enak dan gurih, apalagi bila dimasak dengan ikan yang masih segar. Lokasi cukup sejuk, harga murah.\n","Reference (MAD): berung ngakan e jhelen anggrek roa andik kaistimewaan sabereng kakanan tasek se cem macem ben bede kik odik se phekal e peleh ben e massak bekto roa kea. cem macema jenis masakanna bisa e peleh ben bekto edentek kalaben singkat a ghebey engkok tak terlalu abit kalaparan adentek. menuna toappa kerapu cek nyamanna ben armos, apapole bile e massak bik jukok se gik segger. lokasina cokop cellep, reggena mude.\n","Prediction (MAD): roma ngakan e jelen anggrek riya endik keistimewaan jenis seafood se cem-macem ben bede se ghik hidup ghebey epadeddhi ben eyabes bekto rua kia. bennyak macemma massa'an e pele se abit aghebey engkok abit tak abit kelaparan anante'. menu se kerapu kukuna cek nyaman ben rennya', apa pole mun e pele bik jhile se ghegghel. lokasi cokop sejuk, regghena mude. kenengnganna cokop seggher, ragghana cek ongghu\n","BLEU Score:      2.4715\n","ROUGE-1 Score:   0.3650\n","ROUGE-L Score:   0.3358\n","\n","--- Sample 27 (ID -> MAD) ---\n","Source (ID):     Seperti biasa kami selalu mencari kuliner yang lain daripada yang lain, dapatlah kami di tempat ini yaitu the restaurant padma hotel. Kami memesan menu yang ada. Ada dari indonesia, eropa dan chinese, ternyata semua masakannya enak semuanya.\n","Reference (MAD): Enga' biasana engkok bik selaen kolako nyare kuliner se bhide deri selaen, olle la engkok bik selaen e kennengngan riya iye rua the restaurant padma hotel. Engkok bik selaen messen menu se bede. Bede deri indonesia, eropa ben chinese, nyatana kabbhi massak an nyaman kabbhienna.\n","Prediction (MAD): padena biasa engkok senneng nyare kakanan se laen katemmun se laen, dapatlah engkok bik selaen nyare ka kennengngan riya yaitu the restaurant padma hotel. kami mesen menu se bede. bede deri indonesia, eropa ben chinese, ternyata kabbhienna massa'anna nyaman semuanya. bhuktena nyaman kiya. kodhu ghik. bhekallis. bhehusse.\n","BLEU Score:      24.5605\n","ROUGE-1 Score:   0.4946\n","ROUGE-L Score:   0.4731\n","\n","--- Sample 28 (ID -> MAD) ---\n","Source (ID):     Iya itu yang bikin saya kesal. Ini bukan kesalahan sang pelamar tapi jelas 100% kesalahan pihak yang di atas yang entah bagaimana cara mereka berkordinasi. Nyesek saya itu walaupun ini kasus teman saya yang di lampung.\n","Reference (MAD): Iya rua se ghabay engko' bhallis. Aria banne ka lopotan palamar tape jellas ka lopotan bagian se e attas se baramma cara bagian rua a kordinasi. Nyessek engko' rua maske ria kasos kancana engko' se e lampung.\n","Prediction (MAD): iya rua se ghebey engkok pegghel. ariya benni parjelenan sang pelamar tape jelas 100% kesalahan pihak se e attas se esadiye'eghi laenna pateppa'en. nyesek engkok rua benni pade riya kasus kanca engkok se e lampung. bhuruen engkok bik lampung. lampung. iye rua rua banni' palappa'na engkok. nyobak rua bektona engkok bi' laenna. bhuktena engkok riya bekto engkok arassa' sarah.\n","BLEU Score:      8.0967\n","ROUGE-1 Score:   0.2626\n","ROUGE-L Score:   0.2424\n","\n","--- Sample 29 (ID -> MAD) ---\n","Source (ID):     Pelayanannya agak lama, tetapi suasana yang diberikan keren dan unik, jadi sambil menunggu makanan bisa menikmati suasana di resto ini, menu yang disajikan beragam dan enak,\n","Reference (MAD): Pelayananna bek abit, tape suasana se eberrik keren ben unik, deddhi sambi anante' kakanan bisa anikmati suasana resto riya, menu se esajiye'eghi acem-macem ben nyaman,\n","Prediction (MAD): pelayananna bek abit, tape pangabesen se esare bhegus ben unik, deddhi sambi anantek kakanan bisa anikmati suasana e resto riya, menu se esadiye'eghi acem-macem ben nyaman, daddhi satannaghi pole bannya'.\n","BLEU Score:      40.2079\n","ROUGE-1 Score:   0.7458\n","ROUGE-L Score:   0.7458\n","\n","--- Sample 30 (ID -> MAD) ---\n","Source (ID):     Makanan di sini enak-enak dengan banyak variasi. Semuanya enak dengan pemandangan bagus. Pelayanan yang maksimal dari mbak diah dan gina dari awal datang sampai selesai, dilayani dengan sangat baik.\n","Reference (MAD): Kakanan ediye man-nyaman ben bennyak macemma. Kabbhiena nyaman bik pangabesen bhegus. Pelayanan se paleng bennyak deri mbak diah ben gina deri bhuru deteng sampe' mare, elayani cek bhegusse.\n","Prediction (MAD): kakanan e diye man-nyaman bik bennya' macemma. kabede'en nyaman bik pangabasan bhegus. pelayanan se maksimal deri mbak diah ben gina deri mulae deteng sampe', dilayani bik kanca bhehus. bhekal masennengngenna sarah. bhuktena bhekusse sarah. bhaghusse. bhehseu bi' laenna. bhenderre engkok bik kanca ebherse'. bhersehse.\n","BLEU Score:      12.6507\n","ROUGE-1 Score:   0.4533\n","ROUGE-L Score:   0.4533\n","\n","\n","Madurese -> Indonesian Translations:\n","--- Sample 1 (MAD -> ID) ---\n","Source (MAD):     Semmak bik hotel engkok nginep, pera' ejeleni ajelen soko, ediye bennyak sarah pelean kakananna, kenengngan se leber, ben masenneng\n","Reference (ID): Dekat dengan hotel saya menginap, hanya ditempuh jalan kaki, di sini banyak sekali pilihan makanannya, tempat yang luas, dan menyenangkan\n","Prediction (ID): semmak dengan hotel saya menginap, hanya dengan alas daun, di sini banyak sekali pilihan makanannya, tempat yang luas, dan sangat menyenangkan. sangat direkomendasikan.\n","BLEU Score:      58.3990\n","ROUGE-1 Score:   0.7442\n","ROUGE-L Score:   0.7442\n","\n","--- Sample 2 (MAD -> ID) ---\n","Source (MAD):     Iye bhender, rua ajege berung.\n","Reference (ID): Iya benar, dia sedang jaga warung.\n","Prediction (ID): iye bhender, itu ayam berung. hehehe.\n","BLEU Score:      5.6698\n","ROUGE-1 Score:   0.0000\n","ROUGE-L Score:   0.0000\n","\n","--- Sample 3 (MAD -> ID) ---\n","Source (MAD):     Kangkongnga pendhanan tape kopeteng saos padangnga ma kocaba, engko' bi' laenna e bharri' kopeteng se kopong akherra engko' bi' laenna ta' ngakan kopeteng ban e pabali.\n","Reference (ID): Kangkungnya lumayan tapi kepiting saus padangnya mengecewakan kami dikasih kepiting yang kopong akhir kami tidak makan keptingnya dan dikembalikan.\n","Prediction (ID): makanannya lumayan tapi nasi goreng saos padangnya mengecewakan, saya juga di pesan nasi goreng yang kopongnya saya tidak pernah makan nasi dan di rumah. tidak ada pilihan lain. kurang rekomendasi.\n","BLEU Score:      3.7707\n","ROUGE-1 Score:   0.3265\n","ROUGE-L Score:   0.3265\n","\n","--- Sample 4 (MAD -> ID) ---\n","Source (MAD):     Kenengnganna e braga city walk se settong gheddung bik aston ben fave hotel, kenengngan riya nyaman sarah ghebey tor-catoran. Biddheng campor teh se ludhulluna engkok nginum bhuktena cek nyamanna, ecampor bik tellor massak saparo deddhi pendamping tor-catoran bik ca-kanca. Kenengngan se olle arokok tambe masenneng sambi menikmati pangabesen oreng-oreng se aje'genjir kaluar masok mal riya.\n","Reference (ID): Bertempat di braga city walk yang satu gedung dengan aston dan fave hotel, tempat ini sangat nyaman buat kongkow-kongkow. Kopi campur teh yang baru pertama kali saya nikmati ternyata sangat enak, dipadu dengan telur setengah matang menjadi pendamping mengobrol bersama teman-teman. Area yang bebas merokok semakin mengasyikkan sambil menikmati pemandangan lalu lalang orang-orang yang keluar masuk mal ini.\n","Prediction (ID): tempatnya di braga city walk yang satu lagi dekat dengan aston dan fave hotel, tempat ini sangat nyaman untuk mengobrol. kopi yang disajikan pun sangat enak, ecampor dengan tellor air terjun saparo sebagai pendamping mengobrol dengan teman-teman. tempat yang dapat menikmati pemandangan sungai kecil yang menjadi pemandangan di mal ini. lokasi yang sangat cocok untuk menikmati suasana pedesaan yang hijau. sangat direkomendasikan. tidak perlu pikir dua kali jika mau ke tempat ini lagi.:::.\n","BLEU Score:      21.4514\n","ROUGE-1 Score:   0.4741\n","ROUGE-L Score:   0.4444\n","\n","--- Sample 5 (MAD -> ID) ---\n","Source (MAD):     Gianyar tarema bhantoan sosial 2018 saraja rp 44,9 miliar.\n","Reference (ID): Gianyar terima bantuan sosial 2018 sebesar rp 44, 9 miliar\n","Prediction (ID): gianyar ikuti bhantoan sosial 2018 saraja rp 44,9 miliar. - gianyar\n","BLEU Score:      8.0545\n","ROUGE-1 Score:   0.6667\n","ROUGE-L Score:   0.6667\n","\n","--- Sample 6 (MAD -> ID) ---\n","Source (MAD):     Ariya salah settong conto toronan se tak aghuna. Benni jen aberri' manfaat ghebey bangsa tape jen deddhi bahaya ka bangsa! Mantap tangkep bhei angghuy uu ite\n","Reference (ID): Ini salah satu contoh generasi yang tidak berguna. Bukan malah bermanfaat untuk bangsa tapi malah jadi sesuatu yang berbahaya bagi bangsa! Mantap jerat saja pakai uu ite\n","Prediction (ID): ini salah satu conto masakan yang tidak enak. bukan hanya enak buat bangsa tapi juga bahaya bagi bangsa! mantap tangkep saja revisi uu ite. berbahaya banget uu ite! parah banget!:d\n","BLEU Score:      7.1746\n","ROUGE-1 Score:   0.5172\n","ROUGE-L Score:   0.4828\n","\n","--- Sample 7 (MAD -> ID) ---\n","Source (MAD):     Sore kanca, bekto satiya ghik e lakonin pemeliharaan saengghe aplikasi tak bisa eyangghuy.\n","Reference (ID): Sore sahabat, saat ini sedang dilakukan pemeliharaan sehingga aplikasi tidak dapat diakses.\n","Prediction (ID): sore teman, saat ini sedang di lakonin pemeliharaan sehingga aplikasi tidak bisa dipakai. kurang ajar.\n","BLEU Score:      27.6941\n","ROUGE-1 Score:   0.5926\n","ROUGE-L Score:   0.5926\n","\n","--- Sample 8 (MAD -> ID) ---\n","Source (MAD):     Jhet tak kuat engkok bik bekna riya engkok tako'an kiya saongghuna\n","Reference (ID): Memang lemah kita ini aku juga penakut sebenarnya\n","Prediction (ID): memang tidak kuat saya dengan pasangan ini saya tidak mau tahu juga kenapa?\n","BLEU Score:      3.3772\n","ROUGE-1 Score:   0.2857\n","ROUGE-L Score:   0.2857\n","\n","--- Sample 9 (MAD -> ID) ---\n","Source (MAD):     Terakhir ka hanamasa regghena 120 ebhu per oreng. Tape puassa lebbi deri rua. Bisa ngalak kakanan sapuassa, tape rassana tak mengecewakan, penter-penter kita beih se aracik thibik. Mun penggemar dheghing sape paste senneng ka dinnak.\n","Reference (ID): Terakhir ke hanamasa harganya 120 ribu / orang. Tapi puasnya lebih dari itu. Bisa ambil makanan sepuasnya, tapi rasa tidak mengecewakan, pintar-pintar kita saja meracik sendiri. Kalau penggemar daging sapi pasti suka ke sini\n","Prediction (ID): terakhir ke hanamasa harganya 120 ribu / orang. tapi puas lebih dari itu. bisa makan sepuasnya, tapi rasanya tidak mengecewakan, penter-penter kita juga yang super thibik. kalau penggemar pedas paste suka ke sini.. terima kasih.\n","BLEU Score:      30.4143\n","ROUGE-1 Score:   0.6377\n","ROUGE-L Score:   0.6377\n","\n","--- Sample 10 (MAD -> ID) ---\n","Source (MAD):     Ghabay entar ka the peak jhat karassa jhau ongghu dari pusat kotta bandung ban aksessa se ba' maposang ban jalan kini' lu'-bilu'. Nangeng ba'na mase ta' kera nyasar amargha e sabban bilughan bada tandha nojjhu ka the peak. Kennenganna baghus ongghu ghabay ba'na se nyare pangabasan malem romantis, bik pamandhangan malem kotta se baghus ongghu.\n","Reference (ID): Untuk menuju ke the peak memang terasa sangat jauh dari pusat kota bandung, dan aksesnya yang agak membingungkan dan jalan kecil berkelok-kelok. Namun anda mungkin tidak akan tersesat karena hampir di tiap belokan ada signage menuju ke the peak. Tempatnya sangat bagus untuk anda yang mencari suasana malam romantis, dengan pemandangan malam kota yang menakjubkan.\n","Prediction (ID): untuk pergi ke the peak memang agak sulit dari pusat kota bandung dan akses yang sangat mudah dan jalan yang berliku, serta jalanan yang berliku-liku. namun kenyataannya tidak ada yang nyasar karena di sabban bilughan ada tandha jalan menuju the peak. tempatnya sangat bagus untuk mencari suasana malam romantis, dengan pemandangan malam kota yang sangat indah. rekomendasi banget.::: untuk naik the peak jangan lupa naik tangga.\n","BLEU Score:      23.7689\n","ROUGE-1 Score:   0.6016\n","ROUGE-L Score:   0.5528\n","\n","--- Sample 11 (MAD -> ID) ---\n","Source (MAD):     kebun raya bogor bisa epadeddhi salah settong tojjhuen kennengngan wisata\n","Reference (ID): Kebun raya bogor bisa dijadikan salah satu tujuan destinasi wisata\n","Prediction (ID): kebun raya bogor bisa dijadikan salah satu tempat wisata wisata wisata. semoga bermanfaat.\n","BLEU Score:      33.6493\n","ROUGE-1 Score:   0.6957\n","ROUGE-L Score:   0.6957\n","\n","--- Sample 12 (MAD -> ID) ---\n","Source (MAD):     The peak kenengnganna bede e semmakna lembang, dataran tengghi e bandung se cellep ben kenengngan se bhegus sarah tape jelen ghebey entar ka kenengngan riya akelok sarah ben bhilughen tajhem ben nujjhek, tak esarannaghi ghebey nyetir bekto ojhen ben malem are. E the peak bede restoran bik pangabesen kotta bandung se lebur deri perbukitan, regghe kakanan se larang sarah ben tak cocok sarah.\n","Reference (ID): The peak berlokasi di dekat lembang, dataran tinggi di bandung yang sejuk dan lokasi yang sangat baik namun jalan untuk mencapai tempat ini sangat berkelok disertai tikungan tajam nan curam, tidak disarankan untuk berkendara saat hujan dan malam hari. Di the peak terdapat restoran dengan pemandangan kota bandung yang indah dari perbukitan, harga makanan yang sangat mahal dan sangat tidak sesuai.\n","Prediction (ID): the peak tempatnya terletak di semmakna lembang, dataran tinggi di bandung yang sejuk dan tempat yang sangat indah tetapi jalanan untuk menuju tempat ini sangat curam dan terjal, tidak disarankan untuk mengendarai kendaraan saat malam hari. di the peak ada restoran dengan pemandangan kota bandung yang menawan dari perbukitan, harga makanan yang sangat mahal dan tidak cocok sekali. tidak rekomendasi banget. tidak direkomendasikan!:::\n","BLEU Score:      37.1268\n","ROUGE-1 Score:   0.7097\n","ROUGE-L Score:   0.6774\n","\n","--- Sample 13 (MAD -> ID) ---\n","Source (MAD):     Engkok jherre angghuy jasa lion air\n","Reference (ID): Saya kapok menggunakan jasa lion air\n","Prediction (ID): saya mau tutup jasa lion air. mohon perhatiannya. terima kasih.\n","BLEU Score:      11.4988\n","ROUGE-1 Score:   0.5000\n","ROUGE-L Score:   0.5000\n","\n","--- Sample 14 (MAD -> ID) ---\n","Source (MAD):     Bennyak hal se kaolle engkok bik bekna lakoni ghebey ngesse bekto luang.\n","Reference (ID): Banyak hal yang dapat kita lakukan untuk mengisi waktu luang.\n","Prediction (ID): banyak hal yang telah saya dan suami lakoni untuk mencari waktu luang. tidak banyak yang\n","BLEU Score:      11.9809\n","ROUGE-1 Score:   0.4800\n","ROUGE-L Score:   0.4800\n","\n","--- Sample 15 (MAD -> ID) ---\n","Source (MAD):     Sajen apatis alaporraghi hal-hal mara riya. Polana sampe' minggu beerik ghik pagghun tak elakoni. Pera' jenji-jenji terros.\n","Reference (ID): Semakin apatis melaporkan hal-hal seperti ini. Karena sampai minggu lalu masih tetap belum dikerjakan. Hanya janji-janji terus.\n","Prediction (ID): kasihan banget menuduh hal-hal seperti ini. karena sampe minggu kemarin masih tetap tidak jelas. cuma menuduh-marah terus. tidak konsisten. terus-terusan menghujat. kasihan.\n","BLEU Score:      11.9438\n","ROUGE-1 Score:   0.4091\n","ROUGE-L Score:   0.4091\n","\n","--- Sample 16 (MAD -> ID) ---\n","Source (MAD):     Regghena cek larangngah taninganna sakunnik tak ajenji pole engkok deteng ghebey se dukalena. Massa'anna tak bhide jeuh bik Emakna engkok dong!\n","Reference (ID): Harga selangit porsi seiprit tidak janji lagi saya datang untuk yang kedua kali. Masakannya tidak beda jauh sama ema saya dong!\n","Prediction (ID): harganya sangat mahal namun porsinya luarbiasa jika dibandingkan dengan yang kemarin. masakannya tidak sesuai ekspektasi saya dong! mengecewakan sekali!\n","BLEU Score:      7.3062\n","ROUGE-1 Score:   0.2500\n","ROUGE-L Score:   0.2500\n","\n","--- Sample 17 (MAD -> ID) ---\n","Source (MAD):     Anyar ben la bede, lema' sekat ngakan aben tak-kotak ngakan yooyee kotak sangu se tak mabhucor 590\n","Reference (ID): Baru dan tersedia, 5 sekat makan siang kotak kotak makan yooyee kotak bekal anti bocor 590\n","Prediction (ID): baru dan sudah ada, jangan sekat makan siang tidak-kotak makan yooyee kotak sangu yang tidak terpakai\n","BLEU Score:      15.3848\n","ROUGE-1 Score:   0.5455\n","ROUGE-L Score:   0.5455\n","\n","--- Sample 18 (MAD -> ID) ---\n","Source (MAD):     Tak ngarte ye arapa resto riya ngatoju'i peringkat 12 deri 1800 an resto se bede e jakarta. Regghe larang! lokasina nyelket ngitek, ben rassa kakananna biasa bhei. Jhek pate parcaje ka tinjauan se aghebey kalero lah.\n","Reference (ID): Tidak mengerti ya kenapa resto ini menduduki peringkat 12 dari 1800an resto yang ada di jakarta. Harga mahal! Lokasi tersembunyi, dan rasa makanan biasa saja. Jangan terlalu percaya sama review yang menyesatkanlah.\n","Prediction (ID): tidak suka ya kenapa resto ini menduduki peringkat 12 dari 1800 an resto yang ada di jakarta. harganya mahal! layout menunya biasa saja, dan rasa makanannya biasa saja. jangan percaya dengan ulasan yang membuat jengkel saja. terlalu banyak komplain lah. kurang rekomendasi!:::\n","BLEU Score:      28.4275\n","ROUGE-1 Score:   0.6216\n","ROUGE-L Score:   0.5946\n","\n","--- Sample 19 (MAD -> ID) ---\n","Source (MAD):     Leddhu'en delem aksi protes e afghanistan mamate 68 oreng\n","Reference (ID): Ledakan dalam aksi protes di afghanistan tewaskan 68 orang\n","Prediction (ID): leddhu delem aksi protes di afghanistan menewaskan 68 orang. tidak ada rekomendasi.\n","BLEU Score:      21.1421\n","ROUGE-1 Score:   0.5714\n","ROUGE-L Score:   0.5714\n","\n","--- Sample 20 (MAD -> ID) ---\n","Source (MAD):     Engkok entar ka restoran rua bik kancana engkok. Kancana engkok kabennya'an tagherjet ngabes pangabesenna se lebur sarah e malem are. Engkok endik kasempatan nyoba steak imporra, nyaman sarah apa pole saossa. Mmm yummi. Mun bede kasempatan engkok terro entara pole ka dissa'.\n","Reference (ID): Saya berkunjung ke restoran itu bersama dengan teman saya. Teman saya kebanyakan terkejut melihat pemandangannya yang sangat indah di malam hari. Saya berkesempatan mencoba steak impornya, sangat enak apalagi sausnya. Mmm yummi. Kalau ada kesempatan saya ingin berkunjung lagi ke sana.\n","Prediction (ID): saya berkunjung ke restoran itu bersama teman saya. teman saya semuanya sedang asyik menikmati suasana yang sangat indah di malam hari. saya mendapatkan kesempatan mencoba steak impornya, enak banget apa lagi saosnya. mmm yummi. jika ada kesempatan saya akan kembali ke sana lagi.. tidak ada pilihan lain.:\n","BLEU Score:      27.3712\n","ROUGE-1 Score:   0.6591\n","ROUGE-L Score:   0.6364\n","\n","--- Sample 21 (MAD -> ID) ---\n","Source (MAD):     Jelen nujjhu ka dusun perreng bisa ejeleni rakera delem bekto 1-2 jam angghuy mobil dhibik. Entar ka dusun perreng usaha'aghi bekto compet are polana engkok bik bekna bisa ngabes jelas pangabesen se bede ben bekto se pas ghebey ngakan malem.\n","Reference (ID): Akses menuju dusun bambu bisa ditempuh kira-kira dalam waktu 1 - 2 jam menggunakan mobil pribadi. Berkunjung ke dusun bambu diusahakan saat petang hari karena kita dapat melihat jelas pemandangan yang ada dan waktu yang pas untuk makan malam.\n","Prediction (ID): jelen nujjhu ke dusun perreng bisa ditempuh dalam waktu 1-2 jam menggunakan mobil bekas. pergi ke dusun tersebut untuk usaha kecil-kecil karena kita bisa melihat jelas pemandangan yang ada dan waktu yang pas untuk makan malam. tidak perlu pikir dua kali jika ingin makan siang.\n","BLEU Score:      41.4204\n","ROUGE-1 Score:   0.6047\n","ROUGE-L Score:   0.6047\n","\n","--- Sample 22 (MAD -> ID) ---\n","Source (MAD):     Kakananna oke pade bik xo suki laenna. Tape tekka'na are prei raje padena tellasan riya benni pas misemma prei ben mesen enum, ben en-laen koduh mesen libelien. Tolong e jege kapuasan langghenanna. Kaso'on.\n","Reference (ID): Makanan oke sama seperti xo suki lainnya. Tetapi walaupun hari libur besar seperti lebaran ini bukan berarti senyumnya libur dan order minum, dan lain-lain harus order berkali-kali. Tolong di jaga kepuasan pelanggannya. Terima kasih.\n","Prediction (ID): makanannya oke sama dengan xo suki laenna. tapi walaupun are prei raje seperti di rumah, tetap pas misemma prei dan memesan enum, dan saya harus mesen libelien. tolong dijelaskan detail pesanan. terima kasih. kaso'on.\n","BLEU Score:      4.2594\n","ROUGE-1 Score:   0.3662\n","ROUGE-L Score:   0.3380\n","\n","--- Sample 23 (MAD -> ID) ---\n","Source (MAD):     Restoran riya tamasok kenengngan tojjhuen kuliner se wejib e detengi mun ka bandung. Salaen kakanan se manjaagi jhile kakanan sunda, restoran riya e bangun bik konsep ngakan santai e delem saung se ekalelengi alam alas ben ghunung se ehias papohonan rindang ben e hibur bik suarana aeng songai deddhina mataber aberrik pengalaman kuliner se masenneng sarah. Kodhu e cobak begi sapa'a bhei se ka bandung.\n","Reference (ID): Restoran ini adalah sebuah destinasi kuliner yang wajib dikunjungi bila ke bandung. Selain makanan yang sangat memanjakan lidah makanan sunda, restoran ini juga dibangun dengan konsep makan santai di dalam saung yang dikelilingi alam hutan dan pegunungan yang dihias pepohonan rindang dan dihibur oleh gemericik air sungai sehingga menawarkan pengalaman kuliner yang teramat mengesankan. Harus dicoba bagi siapapun yang ke bandung.\n","Prediction (ID): restoran ini merupakan tempat wisata kuliner yang wajib dikunjungi kalau ke bandung. selain makanan yang khas dengan makanan sunda, restoran ini juga dibangun dengan konsep makan santai di dalam saung yang berada di alam alas dan hutan yang diselimuti pepohonan rindang dan diselimuti air hujan serta suara air sungai yang mengalir membuat pengalaman kuliner ini sangat menyenangkan. harus dicoba terlebih dahulu jika ke bandung, indonesia. tidak perlu menunggu lama untuk datang. harus dipesan terlebih dahulu.\n","BLEU Score:      27.4281\n","ROUGE-1 Score:   0.6176\n","ROUGE-L Score:   0.5735\n","\n","--- Sample 24 (MAD -> ID) ---\n","Source (MAD):     Ngaktiffeghi pole paket data indosat polana olle akses youtube tanpa betes.\n","Reference (ID): Kembali mengaktifkan paket data indosat karena dapat akses youtube unlimited.\n","Prediction (ID): mengaktifkan kembali paket data indosat karena dapat akses youtube tanpa kuota. semoga berguna.. terima kasih.\n","BLEU Score:      32.8252\n","ROUGE-1 Score:   0.7200\n","ROUGE-L Score:   0.6400\n","\n","--- Sample 25 (MAD -> ID) ---\n","Source (MAD):     Engkok bhuru bhei katemmun kanca engkok se alako e trans tv\n","Reference (ID): Saya baru saja bertemu teman saya yang bekerja di trans tv\n","Prediction (ID): saya mau bilang sama teman saya yang bekerja di trans tv. kurang ajar.\n","BLEU Score:      40.0160\n","ROUGE-1 Score:   0.6667\n","ROUGE-L Score:   0.6667\n","\n","--- Sample 26 (MAD -> ID) ---\n","Source (MAD):     berung ngakan e jhelen anggrek roa andik kaistimewaan sabereng kakanan tasek se cem macem ben bede kik odik se phekal e peleh ben e massak bekto roa kea. cem macema jenis masakanna bisa e peleh ben bekto edentek kalaben singkat a ghebey engkok tak terlalu abit kalaparan adentek. menuna toappa kerapu cek nyamanna ben armos, apapole bile e massak bik jukok se gik segger. lokasina cokop cellep, reggena mude.\n","Reference (ID): Rumah makan di jalan anggrek ini memiliki keistimewaan jenis seafood yang beragam dan ada yang masih hidup untuk dipilih dan dimasak saat itu juga. Berbagai jenis masakan dapat dipilih dan waktu tunggu yang singkat membuat kita tidak terlalu lama kelaparan menunggu. Menu kerapu kukusnya sangat enak dan gurih, apalagi bila dimasak dengan ikan yang masih segar. Lokasi cukup sejuk, harga murah.\n","Prediction (ID): makan di warung anggrek menjadikan rumah makan ini sebagai tempat bersantap utama yang beragam dan ada kik kecil yang terlihat di bagian atas dan di bagian bawah. berbagai jenis masakannya bisa dipilih dan dibiarkan dalam waktu singkat sehingga membuat saya tidak terlalu lama menunggu pesanan datang. menunya pun bervariatif enak dan armos, apapole bile disajikan dengan daun pisang yang segar. lokasinya cukup cellep. harga cukup terjangkau. lokasi cukup mudah dijangkau. lokasinya cukup dekat dengan rumah makan lainnya. sangat mudah ditemukan. pilihan menu cukup variatif.\n","BLEU Score:      5.9069\n","ROUGE-1 Score:   0.4414\n","ROUGE-L Score:   0.3862\n","\n","--- Sample 27 (MAD -> ID) ---\n","Source (MAD):     Enga' biasana engkok bik selaen kolako nyare kuliner se bhide deri selaen, olle la engkok bik selaen e kennengngan riya iye rua the restaurant padma hotel. Engkok bik selaen messen menu se bede. Bede deri indonesia, eropa ben chinese, nyatana kabbhi massak an nyaman kabbhienna.\n","Reference (ID): Seperti biasa kami selalu mencari kuliner yang lain daripada yang lain, dapatlah kami di tempat ini yaitu the restaurant padma hotel. Kami memesan menu yang ada. Ada dari indonesia, eropa dan chinese, ternyata semua masakannya enak semuanya.\n","Prediction (ID): tidak biasanya saya dan teman saya mencoba mencari kuliner yang baru dari selaen, akhirnya kami menemukan di tempat ini adalah the restaurant seperti hotel. kami memesan menu yang ada. ada dari indonesia, eropa dan chinese, nyatana semuanya enak semua. jadi terbayarkan dengan nyaman semuanya. tidak ada yang salah dengan tempat ini. kurang rekomendasi.\n","BLEU Score:      21.8650\n","ROUGE-1 Score:   0.5778\n","ROUGE-L Score:   0.5111\n","\n","--- Sample 28 (MAD -> ID) ---\n","Source (MAD):     Iya rua se ghabay engko' bhallis. Aria banne ka lopotan palamar tape jellas ka lopotan bagian se e attas se baramma cara bagian rua a kordinasi. Nyessek engko' rua maske ria kasos kancana engko' se e lampung.\n","Reference (ID): Iya itu yang bikin saya kesal. Ini bukan kesalahan sang pelamar tapi jelas 100% kesalahan pihak yang di atas yang entah bagaimana cara mereka berkordinasi. Nyesek saya itu walaupun ini kasus teman saya yang di lampung.\n","Prediction (ID): iya itu yang bikin saya marah. ini bukan soal lopotan tapi soal lopotingan bagian yang di attas yang sama cara bagian itu dilakukan kordinasi. nyessek saya itu maske ria terima kasih buat teman-teman yang di lampung. terima kasih.:d.\n","BLEU Score:      13.5796\n","ROUGE-1 Score:   0.4737\n","ROUGE-L Score:   0.4737\n","\n","--- Sample 29 (MAD -> ID) ---\n","Source (MAD):     Pelayananna bek abit, tape suasana se eberrik keren ben unik, deddhi sambi anante' kakanan bisa anikmati suasana resto riya, menu se esajiye'eghi acem-macem ben nyaman,\n","Reference (ID): Pelayanannya agak lama, tetapi suasana yang diberikan keren dan unik, jadi sambil menunggu makanan bisa menikmati suasana di resto ini, menu yang disajikan beragam dan enak,\n","Prediction (ID): pelayanan agak lama, tapi suasana yang disajikan keren dan unik, jadi sambil menunggu makanan bisa menikmati suasana resto ini, menu yang disajikan beragam dan enak, serta harga terjangkau. tidak perlu pikir dua kali.\n","BLEU Score:      52.8874\n","ROUGE-1 Score:   0.7458\n","ROUGE-L Score:   0.7458\n","\n","--- Sample 30 (MAD -> ID) ---\n","Source (MAD):     Kakanan ediye man-nyaman ben bennyak macemma. Kabbhiena nyaman bik pangabesen bhegus. Pelayanan se paleng bennyak deri mbak diah ben gina deri bhuru deteng sampe' mare, elayani cek bhegusse.\n","Reference (ID): Makanan di sini enak-enak dengan banyak variasi. Semuanya enak dengan pemandangan bagus. Pelayanan yang maksimal dari mbak diah dan gina dari awal datang sampai selesai, dilayani dengan sangat baik.\n","Prediction (ID): makanan di sini enak dan banyak pilihannya. semuanya enak dengan pemandangan bagus. pelayanan yang cepat dari mbak diah dan gina dari pagi sampai pagi, elayani sangat bagus. info lengkap. silakan cek kembali. terima kasih.\n","BLEU Score:      23.1660\n","ROUGE-1 Score:   0.6250\n","ROUGE-L Score:   0.6250\n","\n"]}],"execution_count":null},{"cell_type":"code","source":"def translate(text: str, direction=\"id2mad\"):\n    text = text.strip()\n    if direction == \"id2mad\":\n        src = \"translate Indonesian to Madurese: \" + text\n    elif direction == \"mad2id\":\n        src = \"translate Madurese to Indonesian: \" + text\n    else:\n        raise ValueError(\"direction harus 'id2mad' atau 'mad2id'\")\n\n    enc = tokenizer(src, return_tensors=\"pt\", truncation=True, max_length=MAX_LEN_SRC).to(device)\n    with torch.no_grad():\n        out = model.generate(**enc, max_new_tokens=MAX_NEW_TOK, num_beams=4)\n    return tokenizer.decode(out[0], skip_special_tokens=True)\n\nwhile True:\n    direction = input(\"\\nPilih arah (id2mad / mad2id) atau ketik q: \").strip()\n    if direction.lower() == \"q\":\n        break\n    text = input(\"Masukkan teks: \").strip()\n    print(\"Hasil:\", translate(text, direction=direction))\n","metadata":{"execution":{"iopub.execute_input":"2025-12-14T12:42:47.140411Z","iopub.status.busy":"2025-12-14T12:42:47.139889Z","iopub.status.idle":"2025-12-14T12:42:50.889209Z","shell.execute_reply":"2025-12-14T12:42:50.888402Z","shell.execute_reply.started":"2025-12-14T12:42:47.140385Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Pilih arah (id2mad / mad2id) atau ketik q:  q\n"]}],"execution_count":64},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/saved_model\")\ntokenizer.save_pretrained(\"/kaggle/working/saved_model\")","metadata":{"execution":{"iopub.execute_input":"2025-12-14T12:42:54.138302Z","iopub.status.busy":"2025-12-14T12:42:54.137542Z","iopub.status.idle":"2025-12-14T12:42:55.452722Z","shell.execute_reply":"2025-12-14T12:42:55.451950Z","shell.execute_reply.started":"2025-12-14T12:42:54.138275Z"},"trusted":true},"outputs":[{"data":{"text/plain":["()"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"execution_count":65},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\nfrom indobenchmark import IndoNLGTokenizer\n\n# load model hasil fine-tuning\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"./saved_model\")\n\n# load tokenizer dari model ASAL (BUKAN saved_model)\ntokenizer = IndoNLGTokenizer.from_pretrained(\"indobenchmark/indobart-v2\")\n","metadata":{"execution":{"iopub.execute_input":"2025-12-14T12:44:32.040527Z","iopub.status.busy":"2025-12-14T12:44:32.039708Z","iopub.status.idle":"2025-12-14T12:44:32.701862Z","shell.execute_reply":"2025-12-14T12:44:32.701041Z","shell.execute_reply.started":"2025-12-14T12:44:32.040495Z"},"trusted":true},"outputs":[],"execution_count":67},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}